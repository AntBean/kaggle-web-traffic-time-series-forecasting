{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n"
     ]
    }
   ],
   "source": [
    "%autosave 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle - Web Traffic Time Series Forecasting\n",
    "\n",
    "## Model 07 - Neural Network with Fibonacci \n",
    "\n",
    "### v7 more days (119 days) as input X\n",
    "\n",
    "by Louis Yang\n",
    "\n",
    "Use Fibonacci series median instead of median\n",
    "\n",
    "Split into groups based on the scale of visit number and train individual model in each group\n",
    "\n",
    "The first 2 groups use original Fibonacci median as prediction. The rest groups use the trained CNN as prediction.\n",
    "\n",
    "Wider the \"model_7_CNN_with_Fibonacci_2_Mix\"\n",
    "\n",
    "Result: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = 'model_7_CNN_with_Fibonacci_7_many_days_0_119_days'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import gc  # Python garbage collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def arr_info(arr_list):\n",
    "    print('shape, min, max, median, stdev')\n",
    "    for arr in arr_list:\n",
    "        print(arr.shape, arr.min(), arr.max(), np.median(arr), arr.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%% Reading data train_1.csv ... done!\n"
     ]
    }
   ],
   "source": [
    "print('%%% Reading data train_1.csv ... ', end = '', flush = True)\n",
    "input_df = pd.read_csv(\"../data/train_1.csv\")\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "input_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "input_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df_dates = input_df.columns[1:]; #input_df_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_data = input_df[input_df_dates].values; input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Data\n",
    "Generate training set and test (predict) set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day of week alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def weekday(datestr):\n",
    "    return datetime.strptime(datestr,'%Y-%m-%d').weekday()\n",
    "def daydiff(dstr1,dstr2):\n",
    "    return datetime.strptime(dstr1,'%Y-%m-%d') - datetime.strptime(dstr2,'%Y-%m-%d') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to predict output (Y_output_pred) start from Sunday (6) for data set 1. (0: Monday, 6: Sunday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We take the x_length + y_length days of data only\n",
    "# This part then split into x_length as input X and y_length as output Y\n",
    "x_length = 119  # input period\n",
    "y_length = 63  # predict period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test_length = 0  # for predicting\n",
    "test_length = y_length  # for self testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shift everything forward by y_length = 63 days to allows self testing without Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_input_dates = input_df_dates[-x_length-test_length-364:-test_length-364]; #X_input_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2015-07-05', '2015-10-31')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_input_first_day = X_input_dates[0]\n",
    "X_input_final_day = X_input_dates[-1]\n",
    "X_input_first_day, X_input_final_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(-118)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daydiff(X_input_first_day, X_input_final_day)  # should be 1 - y_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n"
     ]
    }
   ],
   "source": [
    "# X for output set\n",
    "if test_length:\n",
    "    print('Testing')\n",
    "    X_output_dates = input_df_dates[-x_length-test_length:-test_length]\n",
    "else:\n",
    "    print('Predicting')\n",
    "    X_output_dates = input_df_dates[-x_length:]\n",
    "#X_output_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2016-07-03', '2016-10-29')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_output_first_day = X_output_dates[0]\n",
    "X_output_final_day = X_output_dates[-1]\n",
    "X_output_first_day, X_output_final_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(-118)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daydiff(X_output_first_day, X_output_final_day)  # should be 1 - y_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 6)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekday(X_input_first_day), weekday(X_output_first_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both are Wednesday (2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_input_dates = input_df_dates[-test_length-364:-test_length-364+y_length]; #Y_input_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2015-11-01', '2016-01-02')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_input_first_day = Y_input_dates[0]\n",
    "Y_input_final_day = Y_input_dates[-1]\n",
    "Y_input_first_day, Y_input_final_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(-62)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daydiff(Y_input_first_day, Y_input_final_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y for output set\n",
    "if test_length:\n",
    "    Y_output_dates = input_df_dates[-test_length:]\n",
    "else:\n",
    "    Y_output_first_day = '2017-01-01'\n",
    "    Y_output_dates = pd.Index(np.arange(np.datetime64(Y_output_first_day), \n",
    "                                        np.datetime64(Y_output_first_day)\n",
    "                                        + np.timedelta64(y_length, 'D')).astype('str'))\n",
    "#Y_output_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2016-10-30', '2016-12-31')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_output_first_day = Y_output_dates[0]\n",
    "Y_output_final_day = Y_output_dates[-1]\n",
    "Y_output_first_day, Y_output_final_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(-62)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daydiff(Y_output_first_day, Y_output_final_day)  # should be 1 - y_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 6)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekday(Y_input_first_day), weekday(Y_output_first_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both are Sunday (6)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fibonacci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this testing code, we should not include the last y_length days since in the real predicting stage, we don't know their visits.\n",
    "\n",
    "Here, we don't distinguish between input and output fib_dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_length:\n",
    "    fib_dates = input_df_dates[:-test_length]\n",
    "else:\n",
    "    fib_dates = input_df_dates\n",
    "fib_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fib_data = input_df[fib_dates].values; fib_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find starting dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not using this. Use numpy nan method instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start_tf = ~np.isnan(fib_data); start_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "fib_days = len(fib_data[0]); fib_days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "index_range = np.arange(fib_days)\n",
    "def first_true_index(x):\n",
    "    temp = index_range[x]\n",
    "    if temp.any():\n",
    "        return temp[0]\n",
    "    else:\n",
    "        return -1\n",
    "#first_true_index_v = np.vectorize(first_true_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "start_index = np.array([first_true_index(x) for x in start_tf])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The window sizes are given by Ehsan https://www.kaggle.com/safavieh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "windows = [11, 18, 30, 48, 78, 126, 203, 329]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fib_view_list = [fib_data[:, -w:] for w in windows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fib_median_list = np.array([np.nanmedian(view, axis=-1) \n",
    "                            for view in fib_view_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fib_median_list.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fib_median_na = np.nanmedian(fib_median_list.T, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fib_median_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fib_median = np.nan_to_num(fib_median_na); fib_median.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fib_median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use this as the center and part of the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_output_fib = fib_median.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Selection\n",
    "Select x_length + y_length days of data as input or ouput set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_input_first_day, Y_input_final_day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_data contains X_input and Y_input array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dates = pd.Index(np.concatenate((X_input_dates, Y_input_dates)))\n",
    "input_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = input_df[input_dates].values; input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert nan to number 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_num = np.nan_to_num(input_data); input_data_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_num.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_output_first_day, X_output_final_day, Y_output_final_day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output_data for this self-testing script contains both X_output and Y_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_length:\n",
    "    output_dates = pd.Index(np.concatenate((X_output_dates, Y_output_dates)))\n",
    "else:\n",
    "    output_dates = X_output_dates\n",
    "output_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = input_df[output_dates].values; output_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert nan to number 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data_num = np.nan_to_num(output_data); output_data_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data_num.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def view(x, xlim=None, ylim=None, yscale='linear', title=None, show=True):\n",
    "    plt.yscale(yscale)\n",
    "    plt.plot(x)\n",
    "    if ylim: plt.ylim(ylim)\n",
    "    if xlim: plt.xlim(xlim)\n",
    "    if title: plt.title(title)\n",
    "    if show: plt.show()\n",
    "def viewi(X, i, xlim=None, ylim=None, yscale='linear', show=True):\n",
    "    view(X[i], xlim=xlim, ylim=ylim, yscale=yscale, title='i = ' + str(i), show=show)\n",
    "def examine(X, n=5, xlim=None, ylim=None):\n",
    "    '''randomly show some example in feature and label'''\n",
    "    n_X = len(X)\n",
    "    view_list = np.random.choice(n_X, min(n, n_X), replace=False)\n",
    "    for i in view_list:\n",
    "        viewi(X, i, xlim=xlim, ylim=ylim)\n",
    "    return view_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "examine(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log(X):\n",
    "    return np.log10(X + 1.0)\n",
    "def unlog(X):\n",
    "    return np.clip(np.power(10., X) - 1.0, 0.0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_data_log = log(input_data_num)\n",
    "output_data_log = log(output_data_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check Log transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_log.shape, input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data_log.shape, output_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_data_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output_data_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Check inverse log transformation\n",
    "input_data_log_tt = unlog(input_data_log)\n",
    "input_data_log_tt_dif = input_data_log_tt - input_data_num\n",
    "input_data_log_tt_dif.min(), input_data_log_tt_dif.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Check inverse log transformation\n",
    "output_data_log_tt = unlog(output_data_log)\n",
    "output_data_log_tt_dif = output_data_log_tt - output_data_num\n",
    "output_data_log_tt_dif.min(), output_data_log_tt_dif.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "del input_data_log_tt\n",
    "del input_data_log_tt_dif\n",
    "del output_data_log_tt\n",
    "del output_data_log_tt_dif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization (Shift and Scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Fib Median as the Center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_center = log(fib_median).reshape(-1,1)\n",
    "output_center = log(fib_median).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Median and Stdev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are not using this median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmedian(input_data_log[:,:x_length], axis=-1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_center = np.nanmedian(input_data_log[:,:x_length], axis=-1).reshape(-1,1)\n",
    "input_center  # remember sample-wised center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_scale = np.nanstd(input_data_log[:,:x_length], axis=-1).reshape(-1,1)\n",
    "input_scale[input_scale == 0.0] = 1.0  # Prevent divid by zero\n",
    "input_scale  # remember sample-wised scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output_center = np.nanmedian(output_data_log[:,:x_length], axis=-1).reshape(-1,1)\n",
    "output_center  # remember sample-wised center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "output_scale = np.nanstd(output_data_log[:,:x_length], axis=-1).reshape(-1,1)\n",
    "output_scale[output_scale == 0.0] = 1.0  # Prevent divid by zero\n",
    "output_scale  # remember sample-wised scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check zero in scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Check if there is any 0. in input_scale\n",
    "input_scale[input_scale == 0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Check if there is any 0. in output_scale\n",
    "output_scale[output_scale == 0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shift by Center and Scale by Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform(data_ori, center, scale):\n",
    "    return (data_ori - center) / scale\n",
    "def untransform(data, center, scale):\n",
    "    return data * scale + center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize the input_data and output_data\n",
    "input_data_norm = transform(input_data_log, input_center, input_scale)\n",
    "output_data_norm = transform(output_data_log, output_center, output_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check median and stdev transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_nan(X):\n",
    "    return [x for x in X if np.isnan(x).any()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check_nan(input_data_norm), check_nan(output_data_norm)  # Check if there is any nan in the input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Check inverse scale transformation\n",
    "input_data_norm_it = untransform(input_data_norm, input_center, input_scale)\n",
    "input_data_norm_it_dif = input_data_norm_it - input_data_log\n",
    "input_data_norm_it_dif.min(), input_data_norm_it_dif.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#Check inverse scale transformation\n",
    "output_data_norm_it = untransform(output_data_norm, output_center, output_scale)\n",
    "output_data_norm_it_dif = output_data_norm_it - output_data_log\n",
    "output_data_norm_it_dif.min(), output_data_norm_it_dif.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "del input_data_norm_it\n",
    "del input_data_norm_it_dif\n",
    "del output_data_norm_it\n",
    "del output_data_norm_it_dif\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Center (Median) and Scale (Stdev) Investigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input Center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(input_center, bins=40, alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.hist(input_center, bins=40, alpha=0.6)\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output Center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(output_center, bins=40, alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "plt.hist(output_center, bins=40, alpha=0.6)\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(input_scale, bins=40, normed=True, alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.hist(input_scale, bins=40, alpha=0.6)\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(output_scale, bins=40, normed=True, alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.hist(output_scale, bins=40, alpha=0.6)\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group index based on scale of median (center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_index(logx):\n",
    "    if logx == 0.: return 0\n",
    "    elif logx < 1.0: return 1\n",
    "    elif logx < 2.0: return 2\n",
    "    elif logx < 4.0: return 3\n",
    "    elif logx < 5.0: return 4\n",
    "    else: return 5\n",
    "group_index_v = np.vectorize(group_index)\n",
    "gp_list = list(range(6)); gp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_gp = group_index_v(input_center).reshape(-1)\n",
    "output_gp = group_index_v(output_center).reshape(-1)\n",
    "input_gp, output_gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group counts\n",
    "gp_input_counts = [0] * len(gp_list)\n",
    "for x in input_gp: gp_input_counts[x] += 1\n",
    "gp_input_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group counts\n",
    "gp_output_counts = [0] * len(gp_list)\n",
    "for x in output_gp: gp_output_counts[x] += 1\n",
    "gp_output_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(input_gp, alpha=0.8, label='input')\n",
    "plt.hist(output_gp, alpha=0.3, label='output')\n",
    "plt.yscale('linear')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(input_gp, alpha=0.8, label='input')\n",
    "plt.hist(output_gp, alpha=0.3, label='output')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.hist(input_gp, alpha=0.6)\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.hist(output_gp, alpha=0.6)\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make (X,Y) pairs data from data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "day_shift = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def make_XY(data, x_length=x_length, y_length=y_length, shift=day_shift):\n",
    "    if shift == 0:\n",
    "        return data[:, -x_length-y_length:-y_length], data[:, -y_length:]\n",
    "    else:\n",
    "        return data[:, -x_length-y_length-shift:-y_length-shift], data[:, -y_length-shift:-shift]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_input = input_data_norm[:, :x_length]\n",
    "Y_input = input_data_norm[:, -y_length:]\n",
    "X_input.shape, Y_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_output = output_data_norm[:, :x_length]\n",
    "if test_length:\n",
    "    Y_output = output_data_norm[:, -y_length:]\n",
    "    print(X_output.shape, Y_output.shape)\n",
    "else:\n",
    "    print(X_output.shape, 'No Y_output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_input_ori = input_data_num[:, :x_length]\n",
    "Y_input_ori = input_data_num[:, -y_length:]\n",
    "X_output_ori = output_data_num[:, :x_length]\n",
    "if test_length: \n",
    "    Y_output_ori = output_data_num[:, -y_length:] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw data (with nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_input_raw = input_data[:, :x_length]\n",
    "Y_input_raw = input_data[:, -y_length:]\n",
    "X_output_raw = output_data[:, :x_length]\n",
    "if test_length:\n",
    "    Y_output_raw = output_data[:, -y_length:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward compatible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_input\n",
    "Y_train = Y_input\n",
    "X_val = X_output\n",
    "if test_length:\n",
    "    Y_val = Y_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_ori = X_input_ori\n",
    "Y_train_ori = Y_input_ori\n",
    "X_val_ori = X_output_ori\n",
    "if test_length:\n",
    "    Y_val_ori = Y_output_ori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_scale = input_scale\n",
    "train_center = input_center\n",
    "val_scale = output_scale\n",
    "val_center = output_center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_input, input_data_norm[:,:x_length]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y_input, input_data_norm[:,-y_length:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_output, output_data_norm[:,:x_length]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "if test_length:\n",
    "    print(Y_output)\n",
    "    print(output_data_norm[:,-y_length:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_input_ori, input_data_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y_input_ori, input_data_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_output_ori, output_data_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "if test_length:\n",
    "    print(Y_output_ori)\n",
    "    print(output_data_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if test_length:\n",
    "    arr_info((X_input, Y_input, X_output, Y_output, \n",
    "              X_input_ori, Y_input_ori, X_output_ori, Y_output_ori))\n",
    "else:\n",
    "    arr_info((X_input, Y_input, X_output, \n",
    "              X_input_ori, Y_input_ori, X_output_ori))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Min and max cases examination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.argmax(Y_input, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y_input[34790]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y_input_ori[34790]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "fib_median[34790]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "log(Y_input_ori[34790])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "log(fib_median[34790])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "np.std(log(Y_input_ori[34790]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "np.std(log(X_input_ori[34790]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_scale[34790]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if the inverse transformation is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Undo transformation\n",
    "X_train_tt = unlog(untransform(X_train, train_center, train_scale))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train_tt_diff = X_train_tt - X_train_ori\n",
    "X_train_tt_diff.min(), X_train_tt_diff.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split X,Y data into groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_input[input_gp == 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_input_list = [X_input[input_gp == gp] for gp in gp_list]\n",
    "Y_input_list = [Y_input[input_gp == gp] for gp in gp_list]\n",
    "X_output_list = [X_output[output_gp == gp] for gp in gp_list]\n",
    "if test_length:\n",
    "    Y_output_list = [Y_output[output_gp == gp] for gp in gp_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "#from keras.layers import Conv1D\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.losses import mean_squared_error\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMAPE\n",
    "Symmetric mean absolute percentage error\n",
    "\n",
    "https://en.wikipedia.org/wiki/Symmetric_mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def k_smape(y_true, y_pred):\n",
    "    '''Symmetric mean absolute percentage error for keras metric'''\n",
    "    diff = K.abs((y_true - y_pred) / K.clip(K.abs(y_true) + K.abs(y_pred),\n",
    "                                            K.epsilon(),\n",
    "                                            None))\n",
    "    return 200. * K.mean(diff, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def smape(y_true, y_pred, axis=None):\n",
    "    '''Symmetric mean absolute percentage error'''\n",
    "    diff = np.abs((y_true - y_pred) / \n",
    "                  np.clip(np.abs(y_true) + np.abs(y_pred), K.epsilon(),\n",
    "                          None))\n",
    "    return 200. * np.nanmean(diff, axis=axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def smape_CPMP(y_true, y_pred, axis=None):\n",
    "    '''Symmetric mean absolute percentage error suggested by CPMP'''\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 200.0\n",
    "    diff = np.abs(y_true - y_pred) / denominator\n",
    "    diff[denominator == 0] = 0.0\n",
    "    return np.nanmean(diff, axis=axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smape(np.array([0,1]),np.array([np.nan, 0])), smape(np.array([0]),np.array([0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "smape_CPMP(np.array([0,1]),np.array([np.nan, 0])), smape_CPMP(np.array([0]),np.array([0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Benchmark SMAPE on the transformed data\n",
    "smape(Y_input,X_input), smape(Y_input, X_output), smape(Y_input,Y_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Benchmark SMAPE on the original data\n",
    "smape(Y_input_raw,X_input_ori[:,-y_length:]), smape(Y_input_ori,X_input_ori[:,-y_length:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing better than the first two scores are better than simply copy and past the previous result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Model\n",
    "With the flavor of convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for gp in gp_list:\n",
    "    print('Group:', gp)\n",
    "    layer_0 = Input(shape=(x_length,))\n",
    "    layer_t = Reshape((-1, 1))(layer_0)\n",
    "    layer_t = Conv1D(120, kernel_size=5, activation='relu')(layer_t)\n",
    "    layer_t = MaxPooling1D(pool_size=2)(layer_t)\n",
    "    layer_t = Flatten()(layer_t)\n",
    "    layer_t = Dense(120, activation='relu')(layer_t)\n",
    "    layer_t = Dropout(0.25)(layer_t)\n",
    "    layer_t = Dense(120, activation='relu')(layer_t)\n",
    "    layer_t = Dropout(0.5)(layer_t)\n",
    "    layer_f = Dense(y_length)(layer_t)\n",
    "    model = Model(inputs=layer_0, outputs=layer_f)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mean_squared_error', metrics=[k_smape])\n",
    "    model.summary()\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About 22s for 1 epoch on i5-750 CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs_list = [40,40,40,40,60,80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "hists = []\n",
    "for (gp, model, X_in, Y_in, epochs) in zip(gp_list, models,\n",
    "                                   X_input_list, Y_input_list, \n",
    "                                   epochs_list):\n",
    "    print('Group:',gp)\n",
    "    hist = model.fit(X_in, Y_in, batch_size=128, \n",
    "                     epochs=epochs, \n",
    "                     validation_split=0.05, verbose=2)\n",
    "    #validation_data=(X_val, Y_val))\n",
    "    hists.append(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (hist, gp, ep) in zip(hists, gp_list, epochs_list):\n",
    "    if ep:\n",
    "        plt.plot(hist.history['loss'], label='train')\n",
    "        plt.plot(hist.history['val_loss'], label='validation')\n",
    "        plt.title('Mean Squared Error - ' + str(gp))\n",
    "        plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for (hist, gp, ep) in zip(hists, gp_list, epochs_list):\n",
    "    if ep:\n",
    "        plt.plot(hist.history['k_smape'], label='train')\n",
    "        plt.plot(hist.history['val_k_smape'], label='validation')\n",
    "        plt.title('SMAPE - ' + str(gp))\n",
    "        plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (hist, gp, ep) in zip(hists, gp_list, epochs_list):\n",
    "    if ep: plt.plot(hist.history['loss'], label=gp)\n",
    "plt.title('Mean Squared Error - train')\n",
    "plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (hist, gp, ep) in zip(hists, gp_list, epochs_list):\n",
    "    if ep: plt.plot(hist.history['val_loss'], label=gp)\n",
    "plt.title('Mean Squared Error - validation')\n",
    "plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (hist, gp, ep) in zip(hists, gp_list, epochs_list):\n",
    "    if ep: plt.plot(hist.history['k_smape'], label=gp)\n",
    "plt.title('SMAPE - train')\n",
    "plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (hist, gp, ep) in zip(hists, gp_list, epochs_list):\n",
    "    if ep: plt.plot(hist.history['val_k_smape'], label=gp)\n",
    "plt.title('SMAPE - validation')\n",
    "plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epochs_list2 = [0,10,0,0,10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hists2 = []\n",
    "for (gp, model, X_in, Y_in, epochs) in zip(gp_list, models,\n",
    "                                   X_input_list, Y_input_list, \n",
    "                                   epochs_list2):\n",
    "    hist = model.fit(X_in, Y_in, batch_size=128, \n",
    "                     epochs=epochs, \n",
    "                     validation_split=0.05)\n",
    "    #validation_data=(X_val, Y_val))\n",
    "    hists2.append(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for (hist, gp, epochs) in zip(hists2, gp_list, epochs_list2):\n",
    "    if epochs:\n",
    "        plt.plot(hist.history['loss'], label='train')\n",
    "        plt.plot(hist.history['val_loss'], label='validation')\n",
    "        plt.title('Mean Squared Error - ' + str(gp))\n",
    "        plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "for (hist, gp, epochs) in zip(hists2, gp_list, epochs_list2):\n",
    "    if epochs:\n",
    "        plt.plot(hist.history['k_smape'], label='train')\n",
    "        plt.plot(hist.history['val_k_smape'], label='validation')\n",
    "        plt.title('SMAPE - ' + str(gp))\n",
    "        plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for (hist, gp, epochs) in zip(hists2, gp_list, epochs_list2):\n",
    "    if epochs:\n",
    "        plt.plot(hist.history['loss'], label=gp)\n",
    "plt.title('Mean Squared Error - train')\n",
    "plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for (hist, gp, epochs) in zip(hists2, gp_list, epochs_list2):\n",
    "    if epochs: plt.plot(hist.history['val_loss'], label=gp)\n",
    "plt.title('Mean Squared Error - validation')\n",
    "plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for (hist, gp, epochs) in zip(hists2, gp_list, epochs_list2):\n",
    "    if epochs: plt.plot(hist.history['k_smape'], label=gp)\n",
    "plt.title('SMAPE - train')\n",
    "plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for (hist, gp, epochs) in zip(hists2, gp_list, epochs_list2):\n",
    "    if epochs: plt.plot(hist.history['val_k_smape'], label=gp)\n",
    "plt.title('SMAPE - validation')\n",
    "plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation using for Output Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_length:\n",
    "    for (gp, model, X, Y) in zip(gp_list, models, \n",
    "                                 X_output_list, Y_output_list):\n",
    "        print()\n",
    "        print(model.evaluate(X,Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict for Output Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_output_pred_list = []\n",
    "for (gp, model, X) in zip(gp_list, models, X_output_list):\n",
    "    print(gp)\n",
    "    Y_output_pred_list.append(model.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the original index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_index_range = np.arange(len(output_gp)); output_index_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list for original index\n",
    "output_index_list = [output_index_range[output_gp == gp] \n",
    "                     for gp in gp_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for o in output_index_list:\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_index_list_comb = np.concatenate(output_index_list)\n",
    "output_index_list_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_output_pred_comb = np.concatenate(Y_output_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_output_pred_temp = [0]*len(output_index_list_comb)\n",
    "for index, y in zip(output_index_list_comb, Y_output_pred_comb):\n",
    "    Y_output_pred_temp[index] = y\n",
    "Y_output_pred = np.array(Y_output_pred_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inverse transform Y of output\n",
    "Y_output_pred_ori = unlog(untransform(Y_output_pred, \n",
    "                                      output_center, output_scale))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check predict output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_output_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_output_pred_ori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "examine(Y_output_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "examine(Y_output_pred_ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view(X_output_ori[126420])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMAPE assuming nan == 0\n",
    "if test_length: \n",
    "    model_smape_score_0 = smape(Y_output_ori, Y_output_pred_ori)\n",
    "    print(model_smape_score_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMAPE score excluding nan (Correct one)\n",
    "if test_length: \n",
    "    model_smape_score = smape(Y_output_raw, Y_output_pred_ori)\n",
    "    print(model_smape_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_list#, epochs_list2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Scores\n",
    "For self-testing stage only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prediction Y_output in group\n",
    "Y_output_pred_ori_list = [Y_output_pred_ori[output_gp == gp] for gp in gp_list]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# True Y_output in group\n",
    "if test_length:\n",
    "    # untransformed Y_output with nan replaced by 0\n",
    "    Y_output_ori_list = [Y_output_ori[output_gp == gp] for gp in gp_list]\n",
    "    \n",
    "    # untransformed Y_output_ori with nan (for SMAPE estimation)\n",
    "    Y_output_raw_list = [Y_output_raw[output_gp == gp] for gp in gp_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_n = len(output_gp); tot_n  # total number of pages in output set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_not_nan(data):\n",
    "    return np.count_nonzero(~np.isnan(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_length: print(count_not_nan(Y_output_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Group SMAPE scores\n",
    "if test_length:\n",
    "    gp_n = [len(Y) for Y in Y_output_raw_list]\n",
    "    # SMAPE assuming nan == 0\n",
    "    gp_smape_0 = [smape(Y, Y_p) for Y, Y_p \n",
    "                  in zip(Y_output_ori_list, Y_output_pred_ori_list)]\n",
    "    # SMAPE with nan values ignored (used by Kaggle)\n",
    "    gp_smape = [smape(Y, Y_p) for Y, Y_p \n",
    "                in zip(Y_output_raw_list, Y_output_pred_ori_list)]\n",
    "    \n",
    "    n_not_nan = count_not_nan(Y_output_raw)\n",
    "    n_not_nan_gp = [count_not_nan(Y) for Y in Y_output_raw_list]\n",
    "    n_not_nan_ratio_gp = [n / (len(Y) * len(Y[0])) for Y,n \n",
    "                          in zip(Y_output_raw_list, n_not_nan_gp)]\n",
    "    \n",
    "    # SMAPE contribution\n",
    "    gp_smape_sum = [s * n for n, s in zip(gp_smape, n_not_nan_gp)]\n",
    "    gp_smape_cont = [s / n_not_nan for s in gp_smape_sum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_length:\n",
    "    print('[Group SMAPE]')\n",
    "    print('W/ Nan, Nan=0, Contribution, Pages, Non-nan Ratio')\n",
    "    for score, score_0, c, n, nr in zip(gp_smape, gp_smape_0,\n",
    "                                    gp_smape_cont, gp_n, \n",
    "                                    n_not_nan_ratio_gp):\n",
    "        print('%6.2f' % score, '%6.2f' % score_0, '       %6.2f' % c, '%6d' % n,\n",
    "              '        %6.3f' % nr)\n",
    "    print('-------------------------------------------------')\n",
    "    print('%6.2f' % model_smape_score, '%6.2f' % model_smape_score_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_not_nan_gp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if test_length:\n",
    "    x_tmp = 0.\n",
    "    for Y, Y_p in zip(Y_output_ori_list, Y_output_pred_ori_list):\n",
    "        s_tmp = smape(Y, Y_p) * len(Y)\n",
    "        print(s_tmp / tot_n)\n",
    "        x_tmp += s_tmp\n",
    "    print('SMAPE(0):', '%6.2f' % (x_tmp / tot_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#the correct one (excluding nan)\n",
    "n_not_nan = count_not_nan(Y_output_raw)\n",
    "x_tmp = 0.\n",
    "for Y, Y_p in zip(Y_output_raw_list, Y_output_pred_ori_list):\n",
    "    s_tmp = smape(Y, Y_p) * count_not_nan(Y)\n",
    "    print(s_tmp / n_not_nan)\n",
    "    x_tmp += s_tmp\n",
    "x_tmp / n_not_nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter size| 3| 5| 7| Fib 5\n",
    "-|-|-|-|-\n",
    "0| 7.539| 7.590\t| 7.582| 3.010\n",
    "1| 9.722| 9.855\t| 9.776|11.571\n",
    "2|12.666|12.886\t|13.033|12.167\n",
    "3|20.117|20.323\t|20.295|21.287\n",
    "4| 0.225| 0.226\t| 0.223| 0.321\n",
    "5| 0.015| 0.014\t| 0.014| 0.014\n",
    "Total| 50.283| 50.895| 50.922| 48.371"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Y_input_ori = input_data[:,-y_length:]\n",
    "X_input_ori = input_data[:,:x_length]\n",
    "X_output_ori = output_data[:,:x_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def view(x, xlim=None, ylim=None, yscale='linear', title=None, show=True):\n",
    "    plt.yscale(yscale)\n",
    "    plt.plot(x)\n",
    "    if ylim: plt.ylim(ylim)\n",
    "    if xlim: plt.xlim(xlim)\n",
    "    if title: plt.title(title)\n",
    "    if show: plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def comp_view(x1, x2, title=None, show=True):\n",
    "    plt.plot(x1)\n",
    "    plt.plot(x2)\n",
    "    if title: plt.title(title)\n",
    "    if show: plt.show()\n",
    "\n",
    "def comp_examine(data1, data2, view_n=10, view_list=None):\n",
    "    n_data = len(data1)\n",
    "    if not data1.shape == data2.shape: print(data1.shape, data2.shape, 'not the same length')\n",
    "    if not view_list: view_list = np.random.choice(n_data, min(view_n, n_data), replace=False)\n",
    "    for i in view_list:\n",
    "        comp_view(data1[i], data2[i], title='i = ' + str(i))\n",
    "    return list(view_list)\n",
    "\n",
    "def multi_view(x_list, title=None, show=True, xlim=None, ylim=None, yscale='linear'):\n",
    "    plt.yscale(yscale)\n",
    "    for x in x_list:\n",
    "        plt.plot(x)\n",
    "    if ylim: plt.ylim(ylim)\n",
    "    if xlim: plt.xlim(xlim)\n",
    "    if title: plt.title(title)\n",
    "    if show: plt.show()\n",
    "\n",
    "def examine_list(data_list, view_n=10, view_list=None, xlim=None, ylim=None, yscale='linear'):\n",
    "    n_data = len(data_list[0])\n",
    "    if not view_list: view_list = np.random.choice(n_data, min(view_n, n_data), replace=False)\n",
    "    for i in view_list:\n",
    "        multi_view([data[i] for data in data_list], \n",
    "                   title='i = ' + str(i), xlim=xlim, ylim=ylim, yscale=yscale)\n",
    "    return list(view_list)\n",
    "\n",
    "view_list = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "view_list = comp_examine(X_output, Y_output_pred, view_list=view_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "view_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "view_list = comp_examine(X_output_ori, Y_output_pred_ori, view_list=view_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "view_list = comp_examine(Y_input_ori, Y_output_pred_ori, view_list=view_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if test_length:\n",
    "    view_list = comp_examine(Y_output_ori, Y_output_pred_ori, view_list=view_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "if test_length:\n",
    "    view_list = examine_list((Y_output_pred, Y_output, X_output),\n",
    "                             view_list=view_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if test_length:\n",
    "    view_list = examine_list((Y_output_pred_ori, Y_output_ori, X_output_ori),\n",
    "                             view_list=view_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comp_examine(input_df.iloc[:,-63*2:-63].values,input_df.iloc[:,-63:].values, view_list=view_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_list=[93175, 13986, 5464, 89589, 119659, 64392, 73856, 140331, 19234, 25591]; view_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_list_smape = [smape(Y_output_pred_ori[i], Y_output_raw[i]) for i in view_list]; view_list_smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "view_list_review = [score < model_smape_score for score in view_list_smape]; view_list_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_list_good = list(np.array(view_list)[view_list_review]); view_list_good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_list_bad = list(np.array(view_list)[~np.array(view_list_review)]); view_list_bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Good cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "examine_list((Y_output_pred_ori, Y_output_ori, X_output_ori),\n",
    "             view_list=view_list_good)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bad cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "examine_list((Y_output_pred_ori, Y_output_ori, X_output_ori),\n",
    "             view_list=view_list_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_center[view_list_good].reshape(-1))\n",
    "print(input_center[view_list_bad].reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_gp[view_list_good]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_gp[view_list_bad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gp_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 93175"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "i = 93175"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multi_view((Y_output_pred_ori[i], Y_output_ori[i], X_output_ori[i]), yscale='log')\n",
    "multi_view((Y_output_pred_ori[i], Y_output_ori[i], X_output_ori[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "smape(Y_output_pred_ori[i], Y_output_raw[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 41896"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "i = 41896"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "multi_view((X_input[i], Y_input[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "comp_view(X_input_ori[i], Y_input_ori[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "comp_view(X_output_ori[i], Y_output_pred_ori[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "comp_view(X_input_ori[i], Y_input_ori[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "input_center[i], output_center[i], input_scale[i], output_scale[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMAPE Distribution Investigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMAPE of the model for each data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if test_length:\n",
    "    smape_Y_pred_na = np.array([smape(yp, y) for yp, y \n",
    "                                in zip(Y_output_pred_ori, Y_output_raw)])\n",
    "    smape_Y_pred = np.nan_to_num(smape_Y_pred_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_length:\n",
    "    plt.hist(smape_Y_pred, bins=40, alpha=0.6)\n",
    "    #plt.yscale('log')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if test_length:\n",
    "    smape_Y_pred_list = [smape_Y_pred[output_gp == gp] for gp in gp_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_length:\n",
    "    for i,s in zip(range(len(smape_Y_pred_list)),smape_Y_pred_list):\n",
    "        plt.hist(s, bins=40, normed=True, alpha=0.6, label=str(i))\n",
    "    #plt.yscale('log')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_length:\n",
    "    for i,s in zip(range(len(smape_Y_pred_list)),smape_Y_pred_list):\n",
    "        plt.hist(s, bins=40, normed=True, alpha=0.6, label=str(i))\n",
    "    #plt.yscale('log')\n",
    "    plt.ylim([0,0.05])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_length:\n",
    "    for i,s in zip(range(len(smape_Y_pred_list[1:])),smape_Y_pred_list[1:]):\n",
    "        plt.hist(s, bins=40, normed=True, alpha=0.6, label=str(i+1))\n",
    "    #plt.yscale('log')\n",
    "    plt.ylim([0,0.05])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_length:\n",
    "    for i,s in zip(range(len(smape_Y_pred_list[1:])),smape_Y_pred_list[1:]):\n",
    "        plt.hist(s, bins=40, alpha=0.6, label=str(i+1))\n",
    "    #plt.yscale('log')\n",
    "    #plt.ylim([0,0.05])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if test_length:\n",
    "    for i,s in zip(range(len(smape_Y_pred_list)),smape_Y_pred_list):\n",
    "        plt.hist(s, bins=40, alpha=0.6)\n",
    "        plt.title('gp = '+str(i))\n",
    "        plt.show()\n",
    "    #plt.yscale('log')\n",
    "    #plt.ylim([0,0.05])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMAPE for Fibonacci median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we replace the group 1 prediction by fib median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_output_fib_list = [fib_median[output_gp == gp].reshape(-1,1) \n",
    "                     for gp in gp_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_output_fib_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The actual score with nan\n",
    "if test_length:\n",
    "    gp_smape_fib = [smape(Y, Y_p) for Y, Y_p in zip(Y_output_raw_list, Y_output_fib_list)]\n",
    "    print('Model|', 'Fib|', 'number in the group')\n",
    "    print('-|-|-')\n",
    "    for score1, score2, n in zip(gp_smape, gp_smape_fib, gp_n):\n",
    "        print('%3.3f |'%score1, '%3.3f|'%score2, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model_7_CNN_with_Fibonacci_6_Wider_1_conv_120_Maxpool\n",
    "Model| Fib| number in the group\n",
    "-|-|-\n",
    "187.501 | 115.887| 3422\n",
    "64.454 | 61.823| 23105\n",
    "44.521 | 45.496| 40264\n",
    "38.306 | 40.368| 77416\n",
    "40.331 | 40.033| 790\n",
    "33.218 | 33.144| 66\n",
    "\n",
    "#### model_7_CNN_with_Fibonacci_6_Wider_0_conv_120 2\n",
    "Model| Fib| number in the group\n",
    "-|-|-\n",
    "187.699 | 115.887| 3422\n",
    "64.704 | 61.823| 23105\n",
    "44.602 | 45.496| 40264\n",
    "37.446 | 40.368| 77416\n",
    "41.486 | 40.033| 790\n",
    "32.816 | 33.144| 66\n",
    "\n",
    "#### model_7_CNN_with_Fibonacci_6_Wider_0_conv_120 1\n",
    "Model| Fib| number in the group\n",
    "-|-|-\n",
    "187.234 | 115.887| 3422\n",
    "64.125 | 61.823| 23105\n",
    "45.130 | 45.496| 40264\n",
    "38.651 | 40.368| 77416\n",
    "40.282 | 40.033| 790\n",
    "32.537 | 33.144| 66\n",
    "\n",
    "#### model_7_CNN_with_Fibonacci_5_Deeper_0_Initial 2\n",
    "Model| Fib| number in the group\n",
    "-|-|-\n",
    "189.793 | 115.887| 3422\n",
    "64.655 | 61.823| 23105\n",
    "45.555 | 45.496| 40264\n",
    "38.200 | 40.368| 77416\n",
    "40.980 | 40.033| 790\n",
    "33.561 | 33.144| 66\n",
    "\n",
    "#### model_7_CNN_with_Fibonacci_5_Deeper_0_Initial 1\n",
    "Model| Fib| number in the group\n",
    "-|-|-\n",
    "187.696 | 115.887| 3422\n",
    "65.540 | 61.823| 23105\n",
    "45.246 | 45.496| 40264\n",
    "37.847 | 40.368| 77416\n",
    "41.319 | 40.033| 790\n",
    "32.575 | 33.144| 66\n",
    "\n",
    "#### model_7_CNN_with_Fibonacci_4\n",
    "Model| Fib| number in the group\n",
    "-|-|-\n",
    "152.096 | 115.887| 3422\n",
    "63.372 | 61.823| 23105\n",
    "44.779 | 45.496| 40264\n",
    "37.594 | 40.368| 77416\n",
    "42.546 | 40.033| 790\n",
    "33.056 | 33.144| 66"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Fib do better in group 0 and 1!!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMAPE distribution for Fib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if test_length:\n",
    "    smape_Y_fib_na = np.array([smape(yp, y) for yp, y \n",
    "                               in zip(Y_output_fib, Y_output_raw)])\n",
    "    smape_Y_fib = np.nan_to_num(smape_Y_fib_na)\n",
    "\n",
    "    smape_Y_fib_list = [smape_Y_fib[output_gp == gp] for gp in gp_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_length:\n",
    "    plt.hist(smape_Y_fib, bins=40, alpha=0.6)\n",
    "    plt.hist(smape_Y_pred, bins=40, alpha=0.6)\n",
    "    #plt.yscale('log')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_length:\n",
    "    for i,s in zip(range(len(smape_Y_fib_list)),smape_Y_fib_list):\n",
    "        plt.hist(s, bins=40, normed=True, alpha=0.6, label=str(i))\n",
    "    #plt.yscale('log')\n",
    "    #plt.ylim([0,0.05])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_length:\n",
    "    for i,s in zip(range(len(smape_Y_fib_list[1:])),smape_Y_fib_list[1:]):\n",
    "        plt.hist(s, bins=40, alpha=0.6, label=str(i+1))\n",
    "    #plt.yscale('log')\n",
    "    #plt.ylim([0,0.05])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if test_length:\n",
    "    for i,s in zip(range(len(smape_Y_fib_list)),smape_Y_fib_list):\n",
    "        plt.hist(s, bins=40, alpha=0.6)\n",
    "        plt.title('gp = '+str(i))\n",
    "        plt.show()\n",
    "    #plt.yscale('log')\n",
    "    #plt.ylim([0,0.05])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Combine\n",
    "Combine group 0, 1 from Fib and rest from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_output_fib.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_output_fib_ori = np.repeat(Y_output_fib, y_length, axis=1); Y_output_fib_ori.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select group 0, 1\n",
    "fib_mask = ((output_gp == 0)|(output_gp == 1)).reshape(-1,1); fib_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The combined result\n",
    "Y_output_fmc_ori = fib_mask * Y_output_fib_ori + (~fib_mask) * Y_output_pred_ori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_output_fmc_ori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_length: \n",
    "    model_combined_smape_score = smape(Y_output_fmc_ori, Y_output_raw)\n",
    "    print(model_combined_smape_score, model_smape_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Combined Scores:\n",
    "44.473 (45.652) - Model 7.6.1 - model_7_CNN_with_Fibonacci_6_Wider_1_conv_120_Maxpool\n",
    "\n",
    "44.835 (45.961) - Model 7.6.0 - model_7_CNN_with_Fibonacci_6_Wider_0_conv_120 1\n",
    "\n",
    "44.713 (45.947) - Model 7.5.0 - model_7_CNN_with_Fibonacci_5_Deeper_0_Initial 2\n",
    "\n",
    "44.433          - Model 7.5.0 - model_7_CNN_with_Fibonacci_5_Deeper_0_Initial 1\n",
    "\n",
    "44.168          - Model 7.2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Prediction\n",
    "For predicting stage only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "predict_dates_index=pd.date_range(Y_output_first_day, \n",
    "                                  periods=np.timedelta64(y_length,'D'), \n",
    "                                  freq = 'D', unit = 'D')\n",
    "predict_dates_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_output_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if test_length == 0:\n",
    "    result_df = pd.DataFrame(Y_output_pred_ori, columns = Y_output_dates)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_df['Page'] = input_df['Page']  # Append 'Page' column from input_df\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_flat_df = pd.melt(result_df, id_vars='Page', var_name='date',\n",
    "                         value_name='Visits')\n",
    "result_flat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if test_length == 0:\n",
    "    print('%%% Reading data key_1.csv ...', end = '', flush = True)\n",
    "    output_df = pd.read_csv(\"../data/key_1.csv\")\n",
    "    print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_df['date'] = output_df.Page.apply(lambda a: a[-10:])  # take the last 10 characters from 'Page' as date\n",
    "output_df['Page'] = output_df.Page.apply(lambda a: a[:-11])  # remove the last 10 caharacters from 'Page'\n",
    "#output_df['date'] = output_df['date'].astype('datetime64[ns]')  # convert 'date' string to numpy datetime format\n",
    "#test['weekday'] = test.date.dt.dayofweek  # find the day of week using the 'date' column\n",
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_df['date'].values[0:62]  # Make sure the range is 60 days (see if the dates resume after 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_output_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_df = output_df.merge(result_flat_df, how='left')  # fill the 'Visits\" from result\n",
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del result_flat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Check if there is null value\n",
    "output_df.loc[output_df.Visits.isnull(), 'Visits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#output_df.loc[output_df.Visits.isnull(), 'Visits'] = 0.0  # Uncommend this line to Replace NaN with 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('%%% Writing result for ' + model_name + ' ...', \n",
    "      end = '', flush = True)\n",
    "#Write only the 'Id' and 'Visits' to the result file\n",
    "output_df[['Id','Visits']].to_csv('../results/submit_1_' + model_name\n",
    "                                + '.csv', index = False)\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle LB Score: \n",
    "\n",
    "[6.0.0] 46.3 [Model 6.0.0 CNN - Conv(60, 7)-FC(120)-Drop(0.25)-FC(120)-Drop(0.5)-Linear, 20 epoches]\n",
    "\n",
    "[6.1.0] 46.7 [Model 6.1.0 CNN - Conv(30, 7)-Conv(60, 7)-FC(120)-Drop(0.25)-FC(120)-Drop(0.5)-Linear, 20 epoches]\n",
    "\n",
    "[7.1.2] 47.3 [Model 7.1.2 CNN Fibonacci - range corrected :-y_length - score corrected]\n",
    "\n",
    "[7.2.0] 46.5 [Model 7.2.0 CNN Fibonacci and original combined]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
