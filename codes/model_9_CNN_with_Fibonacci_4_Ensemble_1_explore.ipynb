{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n"
     ]
    }
   ],
   "source": [
    "%autosave 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle - Web Traffic Time Series Forecasting\n",
    "\n",
    "## Model 09 - CNN with Fibonacci \n",
    "\n",
    "### v4 Ensemble\n",
    "\n",
    "by Louis Yang\n",
    "\n",
    "Use Fibonacci series median instead of median. The Fib. median are now compute on both training and CV set separately.\n",
    "\n",
    "Split into groups based on the scale of visit number and train individual model in each group\n",
    "\n",
    "The first 2 groups use original Fibonacci median as prediction. The rest groups use the trained CNN as prediction.\n",
    "\n",
    "Test on stage 2 data.\n",
    "\n",
    "Original model: 'model_7_CNN_with_Fibonacci_8_mean_absolute_error_1_stage_2'\n",
    "\n",
    "Ensemble: automatically evaluate the same model 4 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = 'model_9_CNN_with_Fibonacci_4_Ensemble'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import gc  # Python garbage collect\n",
    "from tools import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_file = 'train_2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%% Reading data train_2.csv ... done!\n"
     ]
    }
   ],
   "source": [
    "print('%%% Reading data '+ train_file + ' ... ', end = '', flush = True)\n",
    "input_df = pd.read_csv('../data/' + train_file)\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_df_dates = input_df.columns[1:]; #input_df_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Data\n",
    "Generate training set and test (predict) set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day of week alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def weekday(datestr):\n",
    "    return datetime.strptime(datestr,'%Y-%m-%d').weekday()\n",
    "def daydiff(dstr1,dstr2):\n",
    "    return datetime.strptime(dstr1,'%Y-%m-%d') - datetime.strptime(dstr2,'%Y-%m-%d') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to predict output (Y_output_pred) start from Sunday (6) for data set 1. (0: Monday, 6: Sunday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We take the x_length + y_length days of data only\n",
    "# This part then split into x_length as input X and y_length as output Y\n",
    "x_length = 63  # input period\n",
    "y_length = 63  # predict period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test_length = 0  # for predicting\n",
    "test_length = y_length  # for self testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shift everything forward by y_length = 63 days to allows self testing without Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_input_dates = input_df_dates[-x_length-test_length-364:-test_length-364]; #X_input_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2016-04-29', '2016-06-30')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_input_first_day = X_input_dates[0]\n",
    "X_input_final_day = X_input_dates[-1]\n",
    "X_input_first_day, X_input_final_day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "daydiff(X_input_first_day, X_input_final_day)  # should be 1 - y_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X for output set\n",
    "if test_length:\n",
    "    X_output_dates = input_df_dates[-x_length-test_length:-test_length]\n",
    "else:\n",
    "    X_output_dates = input_df_dates[-x_length:]\n",
    "#X_output_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2017-04-28', '2017-06-29')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_output_first_day = X_output_dates[0]\n",
    "X_output_final_day = X_output_dates[-1]\n",
    "X_output_first_day, X_output_final_day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "daydiff(X_output_first_day, X_output_final_day)  # should be 1 - y_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weekday(X_input_first_day), weekday(X_output_first_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both are Wednesday (2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_input_dates = input_df_dates[-test_length-364:-test_length-364+y_length]; #Y_input_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2016-07-01', '2016-09-01')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_input_first_day = Y_input_dates[0]\n",
    "Y_input_final_day = Y_input_dates[-1]\n",
    "Y_input_first_day, Y_input_final_day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "daydiff(Y_input_first_day, Y_input_final_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Y for output set\n",
    "if test_length:\n",
    "    Y_output_dates = input_df_dates[-test_length:]\n",
    "else:\n",
    "    Y_output_first_day = '2017-09-12'  ## Make sure it is correct when predicting !!!!!!!\n",
    "    Y_output_dates = pd.Index(np.arange(np.datetime64(Y_output_first_day), \n",
    "                                        np.datetime64(Y_output_first_day)\n",
    "                                        + np.timedelta64(y_length, 'D')).astype('str'))\n",
    "#Y_output_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2017-06-30', '2017-08-31')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_output_first_day = Y_output_dates[0]\n",
    "Y_output_final_day = Y_output_dates[-1]\n",
    "Y_output_first_day, Y_output_final_day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "daydiff(Y_output_first_day, Y_output_final_day)  # should be 1 - y_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weekday(Y_input_first_day), weekday(Y_output_first_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both are Sunday (6)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fibonacci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Window Sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The window sizes are given by Ehsan https://www.kaggle.com/safavieh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "windows = [11, 18, 30, 48, 78, 126, 203, 329]\n",
    "fib_length = max(windows)#; fib_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this testing code, we did not include the last y_length days since in the real predicting stage, we don't know their visits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['2015-08-07', '2015-08-08', '2015-08-09', '2015-08-10', '2015-08-11',\n",
       "        '2015-08-12', '2015-08-13', '2015-08-14', '2015-08-15', '2015-08-16',\n",
       "        ...\n",
       "        '2016-06-21', '2016-06-22', '2016-06-23', '2016-06-24', '2016-06-25',\n",
       "        '2016-06-26', '2016-06-27', '2016-06-28', '2016-06-29', '2016-06-30'],\n",
       "       dtype='object', length=329),\n",
       " Index(['2016-08-05', '2016-08-06', '2016-08-07', '2016-08-08', '2016-08-09',\n",
       "        '2016-08-10', '2016-08-11', '2016-08-12', '2016-08-13', '2016-08-14',\n",
       "        ...\n",
       "        '2017-06-20', '2017-06-21', '2017-06-22', '2017-06-23', '2017-06-24',\n",
       "        '2017-06-25', '2017-06-26', '2017-06-27', '2017-06-28', '2017-06-29'],\n",
       "       dtype='object', length=329))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if test_length:\n",
    "    fib_output_dates = input_df_dates[-fib_length-test_length:-test_length]\n",
    "else:\n",
    "    fib_output_dates = input_df_dates[-fib_length:]\n",
    "fib_input_dates = input_df_dates[-fib_length-test_length-364:-test_length-364]\n",
    "fib_input_dates, fib_output_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekday(fib_input_dates[0]), weekday(fib_output_dates[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  49.,   10.,   19., ...,   32.,   34.,   21.],\n",
       "       [  30.,   16.,   54., ...,  127.,  104.,   20.],\n",
       "       [   7.,    2.,    1., ...,    5.,    5.,    0.],\n",
       "       ..., \n",
       "       [  nan,   nan,   nan, ...,   35.,   46.,   43.],\n",
       "       [  nan,   nan,   nan, ...,    6.,    6.,    7.],\n",
       "       [  nan,   nan,   nan, ...,   21.,   20.,   14.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fib_output_data = input_df[fib_output_dates].values; fib_output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.,  11.,  10., ...,  18.,  23.,  12.],\n",
       "       [  2.,  23.,  12., ...,  24.,  16.,  15.],\n",
       "       [  5.,   1.,   4., ...,   5.,   1.,   4.],\n",
       "       ..., \n",
       "       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "       [ nan,  nan,  nan, ...,  nan,  nan,  nan]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fib_input_data = input_df[fib_input_dates].values; fib_input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fibonacci median in each window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\numpy\\lib\\function_base.py:3858: RuntimeWarning: All-NaN slice encountered\n",
      "  r = func(a, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "fib_input_median_list = np.array([np.nanmedian(fib_input_data[:, -w:] , axis=-1) \n",
    "                            for w in windows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\numpy\\lib\\function_base.py:3858: RuntimeWarning: All-NaN slice encountered\n",
      "  r = func(a, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "fib_output_median_list = np.array([np.nanmedian(fib_output_data[:, -w:] , axis=-1) \n",
    "                            for w in windows])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fib_input_median_list.T.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fib_output_median_na = np.nanmedian(fib_output_median_list.T, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fib_output_median_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\numpy\\lib\\function_base.py:3858: RuntimeWarning: All-NaN slice encountered\n",
      "  r = func(a, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(145063,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fib_input_median = np.nan_to_num(np.nanmedian(fib_input_median_list.T, axis=-1)); fib_input_median.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\numpy\\lib\\function_base.py:3858: RuntimeWarning: All-NaN slice encountered\n",
      "  r = func(a, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(145063,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fib_output_median = np.nan_to_num(np.nanmedian(fib_output_median_list.T, axis=-1)); fib_output_median.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 16.5 ,  15.25,   4.  , ...,   0.  ,   0.  ,   0.  ])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fib_input_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 24.  ,  22.5 ,   4.  , ...,  34.  ,   7.75,  11.25])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fib_output_median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use this as the center and part of the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_input_fib = fib_input_median.reshape(-1,1)\n",
    "Y_output_fib = fib_output_median.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Selection\n",
    "Select x_length + y_length days of data as input or ouput set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_data contains X_input and Y_input array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['2016-04-29', '2016-04-30', '2016-05-01', '2016-05-02', '2016-05-03',\n",
       "        '2016-05-04', '2016-05-05', '2016-05-06', '2016-05-07', '2016-05-08',\n",
       "        ...\n",
       "        '2016-08-23', '2016-08-24', '2016-08-25', '2016-08-26', '2016-08-27',\n",
       "        '2016-08-28', '2016-08-29', '2016-08-30', '2016-08-31', '2016-09-01'],\n",
       "       dtype='object', length=126), '2016-04-29', '2016-09-01')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dates = pd.Index(np.concatenate((X_input_dates, Y_input_dates)))\n",
    "input_dates, X_input_first_day, Y_input_final_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_data = input_df[input_dates].values; #input_data  # input_data with nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert nan to number 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_data_num = np.nan_to_num(input_data); #input_data_num  # intput_data with nan -> 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_data_num.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output_data for this self-testing script contains both X_output and Y_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['2017-04-28', '2017-04-29', '2017-04-30', '2017-05-01', '2017-05-02',\n",
       "        '2017-05-03', '2017-05-04', '2017-05-05', '2017-05-06', '2017-05-07',\n",
       "        ...\n",
       "        '2017-08-22', '2017-08-23', '2017-08-24', '2017-08-25', '2017-08-26',\n",
       "        '2017-08-27', '2017-08-28', '2017-08-29', '2017-08-30', '2017-08-31'],\n",
       "       dtype='object', length=126), '2017-04-28', '2017-06-29', '2017-08-31')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if test_length:\n",
    "    output_dates = pd.Index(np.concatenate((X_output_dates, Y_output_dates)))\n",
    "else:\n",
    "    output_dates = X_output_dates\n",
    "output_dates, X_output_first_day, X_output_final_day, Y_output_final_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_data = input_df[output_dates].values; #output_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert nan to number 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 24.,  20.,  36., ...,  26.,  24.,  21.],\n",
       "       [ 19.,  18.,  12., ...,  29.,  34.,  25.],\n",
       "       [  2.,   0.,   3., ...,   8.,  12.,   9.],\n",
       "       ..., \n",
       "       [ 27.,  84.,  14., ...,  21.,  11.,   9.],\n",
       "       [  7.,  10.,  13., ...,   3.,   9.,   2.],\n",
       "       [ 34.,  16.,  16., ...,   9.,   6.,   5.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data_num = np.nan_to_num(output_data); output_data_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145063, 126)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data_num.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def view(x, xlim=None, ylim=None, yscale='linear', title=None, show=True):\n",
    "    plt.yscale(yscale)\n",
    "    plt.plot(x)\n",
    "    if ylim: plt.ylim(ylim)\n",
    "    if xlim: plt.xlim(xlim)\n",
    "    if title: plt.title(title)\n",
    "    if show: plt.show()\n",
    "        \n",
    "def viewi(X, i, xlim=None, ylim=None, yscale='linear', show=True):\n",
    "    view(X[i], xlim=xlim, ylim=ylim, yscale=yscale, title='i = ' + str(i), show=show)\n",
    "    \n",
    "def examine(X, n=5, xlim=None, ylim=None):\n",
    "    '''randomly show some example in feature and label'''\n",
    "    n_X = len(X)\n",
    "    view_list = np.random.choice(n_X, min(n, n_X), replace=False)\n",
    "    for i in view_list:\n",
    "        viewi(X, i, xlim=xlim, ylim=ylim)\n",
    "    return view_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "examine(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log(X):\n",
    "    return np.log10(X + 1.0)\n",
    "def unlog(X):\n",
    "    return np.clip(np.power(10., X) - 1.0, 0.0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_data_log = log(input_data_num)\n",
    "output_data_log = log(output_data_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check Log transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((145063, 126), (145063, 126), (145063, 126), (145063, 126))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data_log.shape, input_data.shape, output_data_log.shape, output_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_data_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output_data_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Check inverse log transformation\n",
    "input_data_log_tt = unlog(input_data_log)\n",
    "input_data_log_tt_dif = input_data_log_tt - input_data_num\n",
    "input_data_log_tt_dif.min(), input_data_log_tt_dif.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Check inverse log transformation\n",
    "output_data_log_tt = unlog(output_data_log)\n",
    "output_data_log_tt_dif = output_data_log_tt - output_data_num\n",
    "output_data_log_tt_dif.min(), output_data_log_tt_dif.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "del input_data_log_tt\n",
    "del input_data_log_tt_dif\n",
    "del output_data_log_tt\n",
    "del output_data_log_tt_dif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization (Shift and Scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Fib Median as the Center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#input_center = log(fib_input_median).reshape(-1,1)\n",
    "output_center = log(fib_output_median).reshape(-1,1)\n",
    "input_center = output_center  # using output_center instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.39794001],\n",
       "        [ 1.37106786],\n",
       "        [ 0.69897   ],\n",
       "        ..., \n",
       "        [ 1.54406804],\n",
       "        [ 0.94200805],\n",
       "        [ 1.08813609]]), array([[ 1.39794001],\n",
       "        [ 1.37106786],\n",
       "        [ 0.69897   ],\n",
       "        ..., \n",
       "        [ 1.54406804],\n",
       "        [ 0.94200805],\n",
       "        [ 1.08813609]]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_center, output_center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choice of default scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_raw_log = log(input_data)  # log of input_data with nan\n",
    "output_raw_log = log(output_data)  # log of output_data with nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.median(np.nanstd(input_data_log[:,:x_length], axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.mean(np.nanstd(input_data_log[:,:x_length], axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1423: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  keepdims=keepdims)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.17974041809557845"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_input_scale = np.nanmedian(np.nanstd(input_raw_log[:,:x_length], axis=-1))\n",
    "default_input_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1423: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  keepdims=keepdims)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.16425448559207598"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_output_scale = np.nanmedian(np.nanstd(output_raw_log[:,:x_length], axis=-1))\n",
    "default_output_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Median and Stdev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are not using this median as center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_center = np.nanmedian(input_data_log[:,:x_length], axis=-1).reshape(-1,1)\n",
    "input_center  # remember sample-wised center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.22042467],\n",
       "       [ 0.1944303 ],\n",
       "       [ 0.23390395],\n",
       "       ..., \n",
       "       [ 0.17974042],\n",
       "       [ 0.17974042],\n",
       "       [ 0.17974042]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_scale = np.nanstd(input_data_log[:,:x_length], axis=-1).reshape(-1,1)\n",
    "input_scale[input_scale == 0.0] = default_input_scale  # Prevent divid by zero \n",
    "# non-zero value is choose based on the median of other page with non-zero stdev)\n",
    "input_scale  # remember sample-wised scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output_center = np.nanmedian(output_data_log[:,:x_length], axis=-1).reshape(-1,1)\n",
    "output_center  # remember sample-wised center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.15715761],\n",
       "       [ 0.23019142],\n",
       "       [ 0.29932548],\n",
       "       ..., \n",
       "       [ 0.30635028],\n",
       "       [ 0.308769  ],\n",
       "       [ 0.41433723]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_scale = np.nanstd(output_data_log[:,:x_length], axis=-1).reshape(-1,1)\n",
    "output_scale[output_scale == 0.0] = default_output_scale  # Prevent divid by zero\n",
    "output_scale  # remember sample-wised scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check zero in scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Check if there is any 0. in input_scale\n",
    "input_scale[input_scale == 0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Check if there is any 0. in output_scale\n",
    "output_scale[output_scale == 0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shift by Center and Scale by Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform(data_ori, center, scale):\n",
    "    return (data_ori - center) / scale\n",
    "def untransform(data, center, scale):\n",
    "    return data * scale + center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize the input_data and output_data\n",
    "input_data_norm = transform(input_data_log, input_center, input_scale)\n",
    "output_data_norm = transform(output_data_log, output_center, output_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check median and stdev transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_nan(X):\n",
    "    return [x for x in X if np.isnan(x).any()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check_nan(input_data_norm), check_nan(output_data_norm)  # Check if there is any nan in the input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Check inverse scale transformation\n",
    "input_data_norm_it = untransform(input_data_norm, input_center, input_scale)\n",
    "input_data_norm_it_dif = input_data_norm_it - input_data_log\n",
    "input_data_norm_it_dif.min(), input_data_norm_it_dif.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#Check inverse scale transformation\n",
    "output_data_norm_it = untransform(output_data_norm, output_center, output_scale)\n",
    "output_data_norm_it_dif = output_data_norm_it - output_data_log\n",
    "output_data_norm_it_dif.min(), output_data_norm_it_dif.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "del input_data_norm_it\n",
    "del input_data_norm_it_dif\n",
    "del output_data_norm_it\n",
    "del output_data_norm_it_dif\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Center (Median) and Scale (Stdev) Investigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.hist(input_center, bins=40, alpha=0.7, label='input')\n",
    "plt.hist(output_center, bins=40, alpha=0.7, label='output')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.hist(input_center, bins=40, alpha=0.7, label='input')\n",
    "plt.hist(output_center, bins=40, alpha=0.7, label='output')\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.hist(input_scale, bins=40, alpha=0.7, label='input')\n",
    "plt.hist(output_scale, bins=40, alpha=0.7, label='output')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.hist(input_scale, bins=40, alpha=0.7, label='input')\n",
    "plt.hist(output_scale, bins=40, alpha=0.7, label='output')\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group index based on scale of median (center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def group_index(logx):\n",
    "    if logx == 0.: return 0\n",
    "    elif logx < 1.0: return 1\n",
    "    elif logx < 2.0: return 2\n",
    "    elif logx < 4.0: return 3\n",
    "    elif logx < 5.0: return 4\n",
    "    else: return 5\n",
    "group_index_v = np.vectorize(group_index)\n",
    "gp_list = list(range(6)); gp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_gp = group_index_v(input_center).reshape(-1)\n",
    "output_gp = group_index_v(output_center).reshape(-1)\n",
    "#input_gp, output_gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group counts\n",
    "gp_input_counts = [0] * len(gp_list)\n",
    "for x in input_gp: gp_input_counts[x] += 1\n",
    "#gp_input_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group counts\n",
    "gp_output_counts = [0] * len(gp_list)\n",
    "for x in output_gp: gp_output_counts[x] += 1\n",
    "#gp_output_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.hist(input_gp, alpha=0.8, label='input')\n",
    "plt.hist(output_gp, alpha=0.3, label='output')\n",
    "plt.yscale('linear')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.hist(input_gp, alpha=0.8, label='input')\n",
    "plt.hist(output_gp, alpha=0.3, label='output')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make (X,Y) pairs data from data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((145063, 63), (145063, 63))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_input = input_data_norm[:, :x_length]\n",
    "Y_input = input_data_norm[:, -y_length:]\n",
    "X_input.shape, Y_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145063, 63) (145063, 63)\n"
     ]
    }
   ],
   "source": [
    "X_output = output_data_norm[:, :x_length]\n",
    "if test_length:\n",
    "    Y_output = output_data_norm[:, -y_length:]\n",
    "    print(X_output.shape, Y_output.shape)\n",
    "else:\n",
    "    print(X_output.shape, 'No Y_output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_input_ori = input_data_num[:, :x_length]\n",
    "Y_input_ori = input_data_num[:, -y_length:]\n",
    "X_output_ori = output_data_num[:, :x_length]\n",
    "if test_length: \n",
    "    Y_output_ori = output_data_num[:, -y_length:] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw data (with nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_input_raw = input_data[:, :x_length]\n",
    "Y_input_raw = input_data[:, -y_length:]\n",
    "X_output_raw = output_data[:, :x_length]\n",
    "if test_length:\n",
    "    Y_output_raw = output_data[:, -y_length:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward compatible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "X_input = X_input\n",
    "Y_input = Y_input\n",
    "X_val = X_output\n",
    "if test_length:\n",
    "    Y_val = Y_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "X_input_ori = X_input_ori\n",
    "Y_input_ori = Y_input_ori\n",
    "X_val_ori = X_output_ori\n",
    "if test_length:\n",
    "    Y_val_ori = Y_output_ori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "train_scale = input_scale\n",
    "train_center = input_center\n",
    "val_scale = output_scale\n",
    "val_center = output_center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_input, input_data_norm[:,:x_length]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y_input, input_data_norm[:,-y_length:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_output, output_data_norm[:,:x_length]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "if test_length:\n",
    "    print(Y_output)\n",
    "    print(output_data_norm[:,-y_length:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_input_ori, input_data_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y_input_ori, input_data_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_output_ori, output_data_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "if test_length:\n",
    "    print(Y_output_ori)\n",
    "    print(output_data_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape, min, max, median, stdev\n",
      "(145063, 63) -104.945597725 182.183688699 0.0250217121081 3.34816141728\n",
      "(145063, 63) -104.945597725 181.969627538 -0.0156385758122 3.42135990909\n",
      "(145063, 63) -57.3465699314 8.00100800101 0.0 1.27077605981\n",
      "(145063, 63) -1627.7382547 51.3918797946 -0.214767758227 6.0365527548\n",
      "(145063, 63) 0.0 23209383.0 126.0 63765.8619057\n",
      "(145063, 63) 0.0 67264258.0 128.0 155483.953622\n",
      "(145063, 63) 0.0 24630674.0 123.0 65785.6552263\n",
      "(145063, 63) 0.0 18670230.0 113.0 57469.0537846\n"
     ]
    }
   ],
   "source": [
    "if test_length:\n",
    "    arr_info((X_input, Y_input, X_output, Y_output, \n",
    "              X_input_ori, Y_input_ori, X_output_ori, Y_output_ori))\n",
    "else:\n",
    "    arr_info((X_input, Y_input, X_output, \n",
    "              X_input_ori, Y_input_ori, X_output_ori))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Min and max cases examination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.argmin(Y_output, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y_output[8604]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y_output_ori[8604]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fib_output_median[8604]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "log(Y_output_ori[8604])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "log(fib_output_median[8604])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.std(log(Y_output_ori[8604]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.std(log(X_output_ori[8604]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output_scale[8604]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if the inverse transformation is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Undo transformation\n",
    "X_input_tt = unlog(untransform(X_input, train_center, train_scale))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_input_tt_diff = X_input_tt - X_input_ori\n",
    "X_input_tt_diff.min(), X_input_tt_diff.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split X,Y data into groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_input[input_gp == 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_input_list = [X_input[input_gp == gp] for gp in gp_list]\n",
    "Y_input_list = [Y_input[input_gp == gp] for gp in gp_list]\n",
    "X_output_list = [X_output[output_gp == gp] for gp in gp_list]\n",
    "if test_length:\n",
    "    Y_output_list = [Y_output[output_gp == gp] for gp in gp_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "#from keras.layers import Conv1D\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.losses import mean_squared_error\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMAPE\n",
    "Symmetric mean absolute percentage error\n",
    "\n",
    "https://en.wikipedia.org/wiki/Symmetric_mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def k_smape(y_true, y_pred):\n",
    "    '''Symmetric mean absolute percentage error for keras metric'''\n",
    "    diff = K.abs((y_true - y_pred) / K.clip(K.abs(y_true) + K.abs(y_pred),\n",
    "                                            K.epsilon(), None))\n",
    "    return 200. * K.mean(diff, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def smape(y_true, y_pred, axis=None):\n",
    "    '''Symmetric mean absolute percentage error'''\n",
    "    diff = np.abs((y_true - y_pred) / \n",
    "                  np.clip(np.abs(y_true) + np.abs(y_pred), 1e-07, None))\n",
    "    return 200. * np.nanmean(diff, axis=axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200.0, 0.0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smape(np.array([0,1]),np.array([np.nan, 0])), smape(np.array([0]),np.array([0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118.39849931396679, 148.1903381452849, 0.0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Benchmark SMAPE on the transformed data\n",
    "smape(Y_input,X_input), smape(Y_input, X_output), smape(Y_input,Y_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60.417294139521594, 58.828327132034431)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Benchmark SMAPE on the original data\n",
    "smape(Y_input_raw,X_input_ori), smape(Y_input_ori,X_input_ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.9386336667 142.088333627\n"
     ]
    }
   ],
   "source": [
    "if test_length: print(smape(Y_output_raw, X_output_ori), smape(Y_output, X_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48.3250071896\n",
      "40.4041165988\n"
     ]
    }
   ],
   "source": [
    "print(smape(Y_input_raw, Y_input_fib))\n",
    "if test_length: print(smape(Y_output_raw, Y_output_fib))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing better than the first two scores are better than simply copy and past the previous result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Model\n",
    "With the flavor of convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import AveragePooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_ens = 5\n",
    "ens_list = list(range(n_ens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0: Group-0 Group-1 Group-2 Group-3 Group-4 Group-5 \n",
      "Run 1: Group-0 Group-1 Group-2 Group-3 Group-4 Group-5 \n",
      "Run 2: Group-0 Group-1 Group-2 Group-3 Group-4 Group-5 \n",
      "Run 3: Group-0 Group-1 Group-2 Group-3 Group-4 Group-5 \n",
      "Run 4: Group-0 Group-1 Group-2 Group-3 Group-4 Group-5 \n"
     ]
    }
   ],
   "source": [
    "#runbelow\n",
    "models_ens = []\n",
    "for run in ens_list:\n",
    "    print('Run', run, end=': ')\n",
    "    models = []\n",
    "    for gp in gp_list:\n",
    "        print('Group-', gp, sep='', end=' ')\n",
    "        layer_0 = Input(shape=(x_length,))\n",
    "        layer_t = Reshape((-1, 1))(layer_0)\n",
    "        layer_t = Conv1D(120, kernel_size=5, activation='relu')(layer_t)\n",
    "        layer_t = AveragePooling1D(pool_size=2)(layer_t)\n",
    "        layer_t = Flatten()(layer_t)\n",
    "        layer_t = Dense(120, activation='relu')(layer_t)\n",
    "        layer_t = Dropout(0.25)(layer_t)\n",
    "        layer_t = Dense(120, activation='relu')(layer_t)\n",
    "        layer_t = Dropout(0.5)(layer_t)\n",
    "        layer_f = Dense(y_length)(layer_t)\n",
    "        model = Model(inputs=layer_0, outputs=layer_f)\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='mean_absolute_error', metrics=[k_smape])\n",
    "        #model.summary()\n",
    "        models.append(model)\n",
    "    models_ens.append(models)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_37 (InputLayer)        (None, 63)                0         \n",
      "_________________________________________________________________\n",
      "reshape_37 (Reshape)         (None, 63, 1)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 59, 120)           720       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_37 (Averag (None, 29, 120)           0         \n",
      "_________________________________________________________________\n",
      "flatten_37 (Flatten)         (None, 3480)              0         \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 120)               417720    \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 120)               14520     \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 63)                7623      \n",
      "=================================================================\n",
      "Total params: 440,583\n",
      "Trainable params: 440,583\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "models_ens[0][0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 6)"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(models_ens).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs_list = [1,1,40,40,60,80]  # change to smaller epochs later (1,1,20,40,60,80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Run: 0 / 5 ===\n",
      "-- Group: 0 / 6 --\n",
      "Train on 1691 samples, validate on 188 samples\n",
      "Epoch 1/1\n",
      "2s - loss: 0.9396 - k_smape: 195.6031 - val_loss: 0.9731 - val_k_smape: 199.3631\n",
      "-- Group: 1 / 6 --\n",
      "Train on 20776 samples, validate on 2309 samples\n",
      "Epoch 1/1\n",
      "4s - loss: 1.1254 - k_smape: 142.7939 - val_loss: 0.9775 - val_k_smape: 131.4627\n",
      "-- Group: 2 / 6 --\n",
      "Train on 39321 samples, validate on 4370 samples\n",
      "Epoch 1/40\n",
      "8s - loss: 1.3257 - k_smape: 127.4361 - val_loss: 1.0273 - val_k_smape: 114.2821\n",
      "Epoch 2/40\n",
      "7s - loss: 1.2412 - k_smape: 118.1483 - val_loss: 1.0626 - val_k_smape: 119.2520\n",
      "Epoch 3/40\n",
      "7s - loss: 1.2351 - k_smape: 116.4158 - val_loss: 1.0262 - val_k_smape: 120.0243\n",
      "Epoch 4/40\n",
      "7s - loss: 1.2255 - k_smape: 115.9307 - val_loss: 1.0270 - val_k_smape: 116.1384\n",
      "Epoch 5/40\n",
      "7s - loss: 1.2126 - k_smape: 114.7102 - val_loss: 1.0034 - val_k_smape: 115.2378\n",
      "Epoch 6/40\n",
      "7s - loss: 1.2085 - k_smape: 114.5684 - val_loss: 1.0413 - val_k_smape: 117.2268\n",
      "Epoch 7/40\n",
      "7s - loss: 1.2084 - k_smape: 114.4570 - val_loss: 1.0060 - val_k_smape: 114.5909\n",
      "Epoch 8/40\n",
      "7s - loss: 1.2049 - k_smape: 114.1379 - val_loss: 1.0557 - val_k_smape: 120.9645\n",
      "Epoch 9/40\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m   1428\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1429\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1430\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1432\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[0;32m   1077\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1078\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1079\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1080\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2268\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2269\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 778\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 982\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1032\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1037\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hists_ens = []\n",
    "for run, models in zip(ens_list, models_ens):\n",
    "    print('=== Run:', run, '/', len(ens_list), '===')\n",
    "    hists = []\n",
    "    for (gp, model, X_in, Y_in, epochs) in zip(gp_list, models,\n",
    "                                       X_input_list, Y_input_list, \n",
    "                                       epochs_list):\n",
    "        print('-- Group:', gp, '/', len(gp_list), '--')\n",
    "        hist = model.fit(X_in, Y_in, batch_size=128, \n",
    "                         epochs=epochs, \n",
    "                         validation_split=0.1, verbose=2)\n",
    "        #validation_data=(X_val, Y_val))\n",
    "        hists.append(hist)\n",
    "    hists_ens.append(hists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-383-66e89cfb3f41>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mep\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mrun\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mens_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m             \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhists_ens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m             \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Mean Squared Error (Train) - Group'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for gp, ep in zip(gp_list, epochs_list):\n",
    "    if ep:\n",
    "        for run in ens_list:\n",
    "            hist = hists_ens[run][gp]\n",
    "            plt.plot(hist.history['loss'], label=str(run))\n",
    "        plt.title('Mean Squared Error (Train) - Group' + str(gp))\n",
    "        plt.legend(); plt.show()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for gp, ep in zip(gp_list, epochs_list):\n",
    "    if ep:\n",
    "        for run in ens_list:\n",
    "            hist = hists_ens[run][gp]\n",
    "            plt.plot(hist.history['val_loss'], label=str(run))\n",
    "        plt.title('Mean Squared Error (Validation) - Group' + str(gp))\n",
    "        plt.legend(); plt.show()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for gp, ep in zip(gp_list, epochs_list):\n",
    "    if ep:\n",
    "        for run in ens_list:\n",
    "            hist = hists_ens[run][gp]\n",
    "            plt.plot(hist.history['k_smape'], label=str(run))\n",
    "        plt.title('SMAPE (Train) - Group' + str(gp))\n",
    "        plt.legend(); plt.show()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for gp, ep in zip(gp_list, epochs_list):\n",
    "    if ep:\n",
    "        for run in ens_list:\n",
    "            hist = hists_ens[run][gp]\n",
    "            plt.plot(hist.history['val_k_smape'], label=str(run))\n",
    "        plt.title('SMAPE (Validation) - Group' + str(gp))\n",
    "        plt.legend(); plt.show()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for (hist, gp, ep) in zip(hists, gp_list, epochs_list):\n",
    "    if ep:\n",
    "        plt.plot(hist.history['loss'], label='train')\n",
    "        plt.plot(hist.history['val_loss'], label='validation')\n",
    "        plt.title('Mean Squared Error - ' + str(gp))\n",
    "        plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for (hist, gp, ep) in zip(hists, gp_list, epochs_list):\n",
    "    if ep:\n",
    "        plt.plot(hist.history['k_smape'], label='train')\n",
    "        plt.plot(hist.history['val_k_smape'], label='validation')\n",
    "        plt.title('SMAPE - ' + str(gp))\n",
    "        plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (hist, gp, ep) in zip(hists, gp_list, epochs_list):\n",
    "    if ep: plt.plot(hist.history['loss'], label=gp)\n",
    "plt.title('Mean Squared Error - train')\n",
    "plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (hist, gp, ep) in zip(hists, gp_list, epochs_list):\n",
    "    if ep: plt.plot(hist.history['val_loss'], label=gp)\n",
    "plt.title('Mean Squared Error - validation')\n",
    "plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (hist, gp, ep) in zip(hists, gp_list, epochs_list):\n",
    "    if ep: plt.plot(hist.history['k_smape'], label=gp)\n",
    "plt.title('SMAPE - train')\n",
    "plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (hist, gp, ep) in zip(hists, gp_list, epochs_list):\n",
    "    if ep: plt.plot(hist.history['val_k_smape'], label=gp)\n",
    "plt.title('SMAPE - validation')\n",
    "plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epochs_list2 = [0,10,0,0,10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hists2 = []\n",
    "for (gp, model, X_in, Y_in, epochs) in zip(gp_list, models,\n",
    "                                   X_input_list, Y_input_list, \n",
    "                                   epochs_list2):\n",
    "    hist = model.fit(X_in, Y_in, batch_size=128, \n",
    "                     epochs=epochs, \n",
    "                     validation_split=0.05)\n",
    "    #validation_data=(X_val, Y_val))\n",
    "    hists2.append(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for (hist, gp, epochs) in zip(hists2, gp_list, epochs_list2):\n",
    "    if epochs:\n",
    "        plt.plot(hist.history['loss'], label='train')\n",
    "        plt.plot(hist.history['val_loss'], label='validation')\n",
    "        plt.title('Mean Squared Error - ' + str(gp))\n",
    "        plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "for (hist, gp, epochs) in zip(hists2, gp_list, epochs_list2):\n",
    "    if epochs:\n",
    "        plt.plot(hist.history['k_smape'], label='train')\n",
    "        plt.plot(hist.history['val_k_smape'], label='validation')\n",
    "        plt.title('SMAPE - ' + str(gp))\n",
    "        plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for (hist, gp, epochs) in zip(hists2, gp_list, epochs_list2):\n",
    "    if epochs:\n",
    "        plt.plot(hist.history['loss'], label=gp)\n",
    "plt.title('Mean Squared Error - train')\n",
    "plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for (hist, gp, epochs) in zip(hists2, gp_list, epochs_list2):\n",
    "    if epochs: plt.plot(hist.history['val_loss'], label=gp)\n",
    "plt.title('Mean Squared Error - validation')\n",
    "plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for (hist, gp, epochs) in zip(hists2, gp_list, epochs_list2):\n",
    "    if epochs: plt.plot(hist.history['k_smape'], label=gp)\n",
    "plt.title('SMAPE - train')\n",
    "plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for (hist, gp, epochs) in zip(hists2, gp_list, epochs_list2):\n",
    "    if epochs: plt.plot(hist.history['val_k_smape'], label=gp)\n",
    "plt.title('SMAPE - validation')\n",
    "plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict for Validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Y_val_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "examine(Y_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Y_val_pred_ori = unlog(untransform(Y_val_pred, val_center, val_scale))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#SMAPE of the validation set\n",
    "smape(Y_val_ori, Y_val_pred_ori)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def view_val(i):\n",
    "    plt.plot(Y_val_pred_ori[i])\n",
    "    plt.plot(Y_val_ori[i])\n",
    "    plt.plot(X_val_ori[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "view_val(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation using Output Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if test_length:\n",
    "    for (gp, model, X, Y) in zip(gp_list, models, \n",
    "                                 X_output_list, Y_output_list):\n",
    "        print()\n",
    "        print(model.evaluate(X,Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict for Output Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_output_pred_list_ens = []\n",
    "for models, run in zip(models_ens, ens_list):\n",
    "    print('Run', run, end=': ')\n",
    "    Y_output_pred_list = []\n",
    "    for (gp, model, X) in zip(gp_list, models, X_output_list):\n",
    "        print(gp, end=' ')\n",
    "        Y_output_pred_list.append(model.predict(X))\n",
    "    Y_output_pred_list_ens.append(Y_output_pred_list)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the original index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_index_range = np.arange(len(output_gp)); #output_index_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list for original index\n",
    "output_index_list = [output_index_range[output_gp == gp] \n",
    "                     for gp in gp_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for o in output_index_list:\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_index_list_comb = np.concatenate(output_index_list)\n",
    "output_index_list_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_output_pred_ens = []\n",
    "for Y_output_pred_list in Y_output_pred_list_ens:\n",
    "    Y_output_pred_comb = np.concatenate(Y_output_pred_list)\n",
    "    Y_output_pred_temp = [0]*len(output_index_list_comb)\n",
    "\n",
    "    for index, y in zip(output_index_list_comb, Y_output_pred_comb):\n",
    "        Y_output_pred_temp[index] = y\n",
    "\n",
    "    Y_output_pred = np.array(Y_output_pred_temp)  # make it an numpy array (which will also make a copy)\n",
    "    Y_output_pred_ens.append(Y_output_pred)\n",
    "\n",
    "del Y_output_pred_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inverse transform Y of output\n",
    "\n",
    "Y_output_pred_ori_ens = []\n",
    "for Y_output_pred in Y_output_pred_ens:\n",
    "    Y_output_pred_ori = unlog(untransform(Y_output_pred, \n",
    "                                          output_center, output_scale))\n",
    "    Y_output_pred_ori_ens.append(Y_output_pred_ori)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check predict output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y_output_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y_output_pred_ori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "examine(Y_output_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "examine(Y_output_pred_ori)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "view(X_output_ori[126420])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMAPE scores for the model\n",
    "if test_length:\n",
    "    model_smape_ens = []\n",
    "    model_smape_0_ens = []\n",
    "    for Y_output_pred_ori in Y_output_pred_ori_ens:\n",
    "        model_smape = smape(Y_output_raw, Y_output_pred_ori) # SMAPE score excluding nan (Correct one)\n",
    "        model_smape_0 = smape(Y_output_ori, Y_output_pred_ori) # SMAPE assuming nan == 0\n",
    "        print(model_smape, model_smape_0)\n",
    "        \n",
    "        model_smape_ens.append(model_smape)\n",
    "        model_smape_0_ens.append(model_smape_0)\n",
    "    model_smape_ens_mean = np.mean(model_smape_ens)\n",
    "    model_smape_0_ens_mean = np.mean(model_smape_0_ens)\n",
    "    print('-----------')\n",
    "    print(model_smape_ens_mean, model_smape_0_ens_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMAPE score for Fibonacci median\n",
    "if test_length:\n",
    "    fib_smape = smape(Y_output_raw, Y_output_fib)\n",
    "    print(fib_smape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Scores\n",
    "For self-testing stage only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prediction Y_output in group\n",
    "Y_output_pred_ori_list_ens = [[Y_output_pred_ori[output_gp == gp] for gp in gp_list]\n",
    "                              for Y_output_pred_ori in Y_output_pred_ori_ens]\n",
    "#Y_output_pred_ori_list = [Y_output_pred_ori[output_gp == gp] for gp in gp_list]\n",
    "Y_output_pred_ori_list = Y_output_pred_ori_list_ens[-1]  # in case you want to see one of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# True Y_output in group\n",
    "if test_length:\n",
    "    # untransformed Y_output with nan replaced by 0\n",
    "    Y_output_ori_list = [Y_output_ori[output_gp == gp] for gp in gp_list]\n",
    "    \n",
    "    # untransformed Y_output_ori with nan (for SMAPE estimation)\n",
    "    Y_output_raw_list = [Y_output_raw[output_gp == gp] for gp in gp_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_n = len(output_gp); tot_n  # total number of pages in output set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_not_nan(data):\n",
    "    return np.count_nonzero(~np.isnan(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "if test_length: print(count_not_nan(Y_output_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Group SMAPE scores\n",
    "if test_length:\n",
    "    gp_n = [len(Y) for Y in Y_output_raw_list]\n",
    "    # SMAPE assuming nan == 0\n",
    "    #gp_smape_0 = [smape(Y, Y_p) for Y, Y_p \n",
    "    #              in zip(Y_output_ori_list, Y_output_pred_ori_list)]\n",
    "    \n",
    "    # SMAPE with nan values ignored (used by Kaggle)\n",
    "    gp_smape_ens = [[smape(Y, Y_p) for Y, Y_p in zip(Y_output_raw_list, Y_output_pred_ori_list)]\n",
    "                    for Y_output_pred_ori_list in Y_output_pred_ori_list_ens]\n",
    "    gp_smape = gp_smape_ens[-1]\n",
    "    #gp_smape = [smape(Y, Y_p) for Y, Y_p \n",
    "    #            in zip(Y_output_raw_list, Y_output_pred_ori_list)]\n",
    "    \n",
    "    n_not_nan = count_not_nan(Y_output_raw)\n",
    "    n_not_nan_gp = [count_not_nan(Y) for Y in Y_output_raw_list]\n",
    "    n_not_nan_ratio_gp = [n / (len(Y) * len(Y[0])) for Y,n \n",
    "                          in zip(Y_output_raw_list, n_not_nan_gp)]\n",
    "    \n",
    "    # SMAPE contribution\n",
    "    #gp_smape_sum = [s * n for n, s in zip(gp_smape, n_not_nan_gp)]\n",
    "    #gp_smape_cont = [s / n_not_nan for s in gp_smape_sum]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if test_length:\n",
    "    print('[Group SMAPE]')\n",
    "    print('W/ Nan, Nan=0, Contribution, Pages, Non-nan Ratio')\n",
    "    for score, score_0, c, n, nr in zip(gp_smape, gp_smape_0,\n",
    "                                    gp_smape_cont, gp_n, \n",
    "                                    n_not_nan_ratio_gp):\n",
    "        print('%6.2f' % score, '%6.2f' % score_0, '       %6.2f' % c, '%6d' % n,\n",
    "              '        %6.3f' % nr)\n",
    "    print('-------------------------------------------------')\n",
    "    print('%6.2f' % model_smape, '%6.2f' % model_smape_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_not_nan_gp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Page Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if test_length:\n",
    "    smape_Y_pred_ens = []\n",
    "    #smape_Y_pred_na = np.array([smape(yp, y) for yp, y \n",
    "    #                            in zip(Y_output_pred_ori, Y_output_raw)])\n",
    "    for Y_output_pred_ori in Y_output_pred_ori_ens:\n",
    "        smape_Y_pred = np.nan_to_num(np.array([smape(yp, y) for yp, y \n",
    "                                               in zip(Y_output_pred_ori, Y_output_raw)]))\n",
    "        smape_Y_pred_ens.append(smape_Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_length:\n",
    "    for smape_Y_pred in smape_Y_pred_ens:\n",
    "        plt.hist(smape_Y_pred, bins=40, alpha=0.4)\n",
    "        #plt.yscale('log')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMAPE for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if test_length:\n",
    "    smape_Y_pred_list_ens = []\n",
    "    for smape_Y_pred in smape_Y_pred_ens:\n",
    "        smape_Y_pred_list = [smape_Y_pred[output_gp == gp] for gp in gp_list]\n",
    "        smape_Y_pred_list_ens.append(smape_Y_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_length:\n",
    "    for i,s in zip(range(len(smape_Y_pred_list)),smape_Y_pred_list):\n",
    "        plt.hist(s, bins=40, normed=True, alpha=0.6, label=str(i))\n",
    "    #plt.yscale('log')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_length:\n",
    "    for i,s in zip(range(len(smape_Y_pred_list)),smape_Y_pred_list):\n",
    "        plt.hist(s, bins=40, normed=True, alpha=0.6, label=str(i))\n",
    "    #plt.yscale('log')\n",
    "    plt.ylim([0,0.05])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_length:\n",
    "    for i,s in zip(range(len(smape_Y_pred_list[1:])),smape_Y_pred_list[1:]):\n",
    "        plt.hist(s, bins=40, normed=True, alpha=0.6, label=str(i+1))\n",
    "    #plt.yscale('log')\n",
    "    plt.ylim([0,0.05])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_length:\n",
    "    for i,s in zip(range(len(smape_Y_pred_list[1:])),smape_Y_pred_list[1:]):\n",
    "        plt.hist(s, bins=40, alpha=0.6, label=str(i+1))\n",
    "    #plt.yscale('log')\n",
    "    #plt.ylim([0,0.05])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if test_length:\n",
    "    for i,s in zip(range(len(smape_Y_pred_list)),smape_Y_pred_list):\n",
    "        plt.hist(s, bins=40, alpha=0.6)\n",
    "        plt.title('gp = '+str(i))\n",
    "        plt.show()\n",
    "    #plt.yscale('log')\n",
    "    #plt.ylim([0,0.05])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMAPE for Fibonacci median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_output_fib_list = [Y_output_fib[output_gp == gp] for gp in gp_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Group SMAPE for Fib.\n",
    "if test_length:\n",
    "    gp_smape_fib = [smape(Y, Y_p) for Y, Y_p in zip(Y_output_raw_list, Y_output_fib_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Individual SMAPE for Fib.\n",
    "if test_length:\n",
    "    #smape_Y_fib_na = np.array([smape(yp, y) for yp, y \n",
    "    #                           in zip(Y_output_fib, Y_output_raw)])\n",
    "    smape_Y_fib = np.nan_to_num(np.array([smape(yp, y) for yp, y \n",
    "                                          in zip(Y_output_fib, Y_output_raw)]))\n",
    "\n",
    "    smape_Y_fib_list = [smape_Y_fib[output_gp == gp] for gp in gp_list]\n",
    "# The above two cells can be combined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMAPE distribution for Fib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_length:\n",
    "    plt.hist(smape_Y_fib, bins=40, alpha=0.6)\n",
    "    plt.hist(smape_Y_pred, bins=40, alpha=0.6)\n",
    "    #plt.yscale('log')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_length:\n",
    "    for i,s in zip(range(len(smape_Y_fib_list)),smape_Y_fib_list):\n",
    "        plt.hist(s, bins=40, normed=True, alpha=0.6, label=str(i))\n",
    "    #plt.yscale('log')\n",
    "    #plt.ylim([0,0.05])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_length:\n",
    "    for i,s in zip(range(len(smape_Y_fib_list[1:])),smape_Y_fib_list[1:]):\n",
    "        plt.hist(s, bins=40, alpha=0.6, label=str(i+1))\n",
    "    #plt.yscale('log')\n",
    "    #plt.ylim([0,0.05])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "source": [
    "if test_length:\n",
    "    for i in range(len(smape_Y_fib_list)):\n",
    "        plt.hist(smape_Y_pred_list[i], bins=40, alpha=0.7, label='Model')\n",
    "        plt.hist(smape_Y_fib_list[i], bins=40, alpha=0.5, label='Fib')\n",
    "        plt.title('gp = '+str(i))\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    #plt.yscale('log')\n",
    "    #plt.ylim([0,0.05])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models vs Fibonacci Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if test_length:\n",
    "    print('#### ' + model_name)\n",
    "    print('', end='|')\n",
    "    print('N_pages ', 'Fibonacci', sep='|', end='|')\n",
    "    for run in ens_list: print(' Model', run, end=' |')\n",
    "    print('')\n",
    "    print('', end='|')\n",
    "    print('--------', '---------', sep='|', end='|')\n",
    "    for run in ens_list: print('---------', end='|')\n",
    "    print('')\n",
    "    for gp in gp_list:\n",
    "        print('', end='|')\n",
    "        print(' %6d ' % gp_n[gp], end='|')\n",
    "        print(' %7.3f ' % gp_smape_fib[gp], end='|')\n",
    "        for run in ens_list:\n",
    "            print(' %7.3f ' % gp_smape_ens[run][gp], end='|')\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model_9_CNN_with_Fibonacci_4_Ensemble\n",
    "|N_pages |Fibonacci| Model 0 |\n",
    "|--------|---------|---------|\n",
    "|   1879 |  57.385 | 146.145 |\n",
    "|  23085 |  61.354 |  64.128 |\n",
    "|  43691 |  40.612 |  40.052 |\n",
    "|  75617 |  34.284 |  29.862 |\n",
    "|    740 |  35.621 |  34.607 |\n",
    "|     51 |  20.224 |  16.023 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Combine\n",
    "Combine group 0, 1 from Fib and rest from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_output_fib.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_output_fib_ori = np.repeat(Y_output_fib, y_length, axis=1); Y_output_fib_ori.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select group 0, 1\n",
    "fib_mask = ((output_gp == 0)|(output_gp == 1)).reshape(-1,1); fib_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The combined result\n",
    "Y_output_fmc_ori_ens = []\n",
    "for Y_output_pred_ori in Y_output_pred_ori_ens:\n",
    "    \n",
    "    Y_output_fmc_ori = fib_mask * Y_output_fib_ori + (~fib_mask) * Y_output_pred_ori\n",
    "    \n",
    "    Y_output_fmc_ori_ens.append(Y_output_fmc_ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_output_fmc_ori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_smape_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_length: \n",
    "    fmc_smape_ens = []\n",
    "    for Y_output_fmc_ori in Y_output_fmc_ori_ens:\n",
    "        fmc_smape = smape(Y_output_fmc_ori, Y_output_raw)\n",
    "        fmc_smape_ens.append(fmc_smape)        \n",
    "    fmc_smape_ens_mean = np.mean(fmc_smape_ens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_length: \n",
    "    for run, fmc_smape, model_smape in zip(ens_list, fmc_smape_ens, model_smape_ens):\n",
    "        print('%6.3f' % fmc_smape, '(%6.3f)' % model_smape, '-', model_name, run)\n",
    "    print('%6.3f' % fmc_smape_ens_mean, '(%6.3f)' % model_smape_ens_mean, '-', model_name, 'Average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Combined Scores:\n",
    "38.777 (39.377) - Model 9.1.0 - model_9_CNN_with_Fibonacci_1_no_group 2\n",
    "\n",
    "38.734 (39.415) - Model 9.1.0 - model_9_CNN_with_Fibonacci_1_no_group 1\n",
    "\n",
    "38.227 (39.321) - Model 9.0.0 - model_9_CNN_with_Fibonacci_0_separate_Fib_median 1\n",
    "\n",
    "43.174 (44.159) - Model 7.8.0 - model_7_CNN_with_Fibonacci_8_mean_absolute_error 3\n",
    "\n",
    "43.009 (44.180) - Model 7.8.0 - model_7_CNN_with_Fibonacci_8_mean_absolute_error 2\n",
    "\n",
    "43.038 (43.990) - Model 7.8.0 - model_7_CNN_with_Fibonacci_8_mean_absolute_error 1\n",
    "\n",
    "43.479 (44.659) - Model 7.6.3 - model_7_CNN_with_Fibonacci_6_Wider_3_conv_120_Averagepool 3\n",
    "\n",
    "43.804 (45.033) - Model 7.6.3 - model_7_CNN_with_Fibonacci_6_Wider_3_conv_120_Averagepool 2\n",
    "\n",
    "44.070 (45.335) - Model 7.6.3 - model_7_CNN_with_Fibonacci_6_Wider_3_conv_120_Averagepool 1\n",
    "\n",
    "44.948 (46.090) - Model 7.6.1 - model_7_CNN_with_Fibonacci_6_Wider_1_conv_120_Maxpool 4\n",
    "\n",
    "43.762 (44.885) - Model 7.6.1 - model_7_CNN_with_Fibonacci_6_Wider_1_conv_120_Maxpool 3\n",
    "\n",
    "43.805 (44.996) - Model 7.6.1 - model_7_CNN_with_Fibonacci_6_Wider_1_conv_120_Maxpool 2\n",
    "\n",
    "44.473 (45.652) - Model 7.6.1 - model_7_CNN_with_Fibonacci_6_Wider_1_conv_120_Maxpool 1\n",
    "\n",
    "44.433 - Model 7.5.0 - model_7_CNN_with_Fibonacci_5_Deeper_0_Initial\n",
    "\n",
    "44.168 - Model 7.2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_output_pred_ori_ens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1 - Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_output_pred_ori_ens_mean = np.mean(Y_output_pred_ori_ens, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_output_pred_ori_ens_mean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y_output_pred_ori_ens_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "smape(Y_output_pred_ori_ens_mean, Y_output_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2 - Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_output_pred_ori_ens_med = np.median(Y_output_pred_ori_ens, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_output_pred_ori_ens_med.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y_output_pred_ori_ens_med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smape(Y_output_pred_ori_ens_med, Y_output_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3 - Mean before inverse transform and log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_output_pred_ens_mean = np.mean(Y_output_pred_ens, axis=0)\n",
    "Y_output_pred_ens_mean_ori = unlog(untransform(Y_output_pred_ens_mean, output_center, output_scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "smape(Y_output_pred_ens_mean_ori, Y_output_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 4 - Median before inverse transform and log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_output_pred_ens_med = np.median(Y_output_pred_ens, axis=0)\n",
    "Y_output_pred_ens_med_ori = unlog(untransform(Y_output_pred_ens_med, output_center, output_scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smape(Y_output_pred_ens_med_ori, Y_output_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best one seems to be taking ensemble average before inverse transform and log!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Combine with Fibonacci Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select group 0, 1\n",
    "fib_mask = ((output_gp == 0)|(output_gp == 1)).reshape(-1,1); fib_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The combined result\n",
    "\n",
    "Y_output_fmc_ori = fib_mask * Y_output_fib_ori + (~fib_mask) * Y_output_pred_ori\n",
    "Y_output_pred_ens_med_ori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_output_f_omean = fib_mask * Y_output_fib_ori + (~fib_mask) * Y_output_pred_ori_ens_mean\n",
    "Y_output_f_omed  = fib_mask * Y_output_fib_ori + (~fib_mask) * Y_output_pred_ori_ens_med\n",
    "Y_output_f_meano = fib_mask * Y_output_fib_ori + (~fib_mask) * Y_output_pred_ens_mean_ori\n",
    "Y_output_f_medo  = fib_mask * Y_output_fib_ori + (~fib_mask) * Y_output_pred_ens_med_ori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smape(Y_output_raw, Y_output_f_omean), smape(Y_output_raw, Y_output_f_omed), smape(Y_output_raw, Y_output_f_meano), smape(Y_output_raw, Y_output_f_medo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmc_smape_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmc_smape_ens_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Y_output_ori_list = [Y_output_ori[output_gp == gp] for gp in gp_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_list=[93175, 13986, 5464, 89589, 119659, 64392, 73856, 140331, 19234, 25591]; view_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_list = examine_list_gp((Y_output_pred_ori_ens_mean, \n",
    "                             Y_output_pred_ori_ens_med,\n",
    "                             Y_output_pred_ori_ens[-1], \n",
    "                             Y_output_ori), output_gp, view_list=view_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 93175\n",
    "plt.plot(Y_output_ori[i], label='true')\n",
    "plt.plot(Y_output_pred_ori_ens_mean[i], label='ens mean')\n",
    "plt.plot(Y_output_pred_ori_ens_med[i], label='ens median')\n",
    "plt.plot(Y_output_pred_ens_mean_ori[i], label='ens mean before transf')\n",
    "plt.plot(Y_output_pred_ens_med_ori[i], label='ens median before transf')\n",
    "plt.plot(Y_output_pred_ori_ens[-1][i], label='run: 4')\n",
    "plt.title('i = ' + str(i) + ' gp = ' + str(output_gp[i]))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 93175\n",
    "plt.plot(Y_output_ori[i], label='true')\n",
    "for run in ens_list:\n",
    "    plt.plot(Y_output_pred_ori_ens[run][i], label='run' + str(run))\n",
    "plt.plot(Y_output_pred_ens_mean_ori[i], label='ens mean before transf')\n",
    "plt.title('i = ' + str(i) + ' gp = ' + str(output_gp[i]))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_list = examine_list_gp((Y_output_pred_ori_ens_mean, \n",
    "                             Y_output_pred_ori_ens_med,\n",
    "                             Y_output_pred_ori_ens[-1], \n",
    "                             Y_output_ori), output_gp, view_list=view_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "view_list = comp_examine(X_output, Y_output_pred, view_list=view_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "view_list = comp_examine(X_output_ori, Y_output_pred_ori, view_list=view_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_list = examine_list_gp((Y_output_pred_ori, X_output_ori, Y_input_ori), output_gp, view_list=view_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_list = examine_list_gp((Y_output_pred, X_output, Y_input), output_gp, view_list=view_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if test_length:\n",
    "    view_list = examine_list((Y_output_pred, Y_output, X_output), view_list=view_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if test_length:\n",
    "    view_list = examine_list((Y_output_pred_ori, Y_output_ori, X_output_ori), view_list=view_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if test_length:\n",
    "    view_list = examine_list_gp((Y_output_pred, Y_output, X_output), output_gp,\n",
    "                             view_list=view_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if test_length:\n",
    "    view_list = examine_list_gp((Y_output_pred_ori, Y_output_ori, X_output_ori), output_gp,\n",
    "                             view_list=view_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_list_smape = [smape(Y_output_pred_ori[i], Y_output_raw[i]) for i in view_list]; view_list_smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "view_list_review = [score < model_smape for score in view_list_smape]; view_list_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_list_good = list(np.array(view_list)[view_list_review]); view_list_good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_list_bad = list(np.array(view_list)[~np.array(view_list_review)]); view_list_bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Good cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "examine_list_gp((Y_output_pred_ori, Y_output_ori, X_output_ori), output_gp,\n",
    "             view_list=view_list_good)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bad cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "examine_list_gp((Y_output_pred_ori, Y_output_ori, X_output_ori),output_gp,\n",
    "             view_list=view_list_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_center[view_list_good].reshape(-1))\n",
    "print(output_center[view_list_bad].reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_scale[view_list_good].reshape(-1))\n",
    "print(output_scale[view_list_bad].reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_gp[view_list_good]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_gp[view_list_bad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gp_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 93175"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 93175"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_view((Y_output_pred_ori[i], Y_output_ori[i], X_output_ori[i]), yscale='log')\n",
    "multi_view((Y_output_pred_ori[i], Y_output_ori[i], X_output_ori[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smape(Y_output_pred_ori[i], Y_output_raw[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "input_center[i], output_center[i], input_scale[i], output_scale[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 41896"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "i = 41896"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "multi_view((X_input[i], Y_input[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "comp_view(X_input_ori[i], Y_input_ori[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "comp_view(X_output_ori[i], Y_output_pred_ori[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "comp_view(X_input_ori[i], Y_input_ori[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good and bad cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review_Y = np.array([score < model_smape for score in smape_Y_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(len(Y_output_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_Y_index = np.arange(len(Y_output_pred))[review_Y]; good_Y_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bad_Y_index = np.arange(len(Y_output_pred))[~review_Y]; bad_Y_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_input_scale = input_scale[good_Y_index]\n",
    "good_output_scale = output_scale[good_Y_index]\n",
    "bad_input_scale = input_scale[bad_Y_index]\n",
    "bad_output_scale = output_scale[bad_Y_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_input_center = input_center[good_Y_index]\n",
    "good_output_center = output_center[good_Y_index]\n",
    "bad_input_center = input_center[bad_Y_index]\n",
    "bad_output_center = output_center[bad_Y_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examine_list_gp((Y_output_pred_ori[good_Y_index], Y_output_ori[good_Y_index], X_output_ori[good_Y_index]), output_gp[good_Y_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "examine_list_gp((Y_output_pred_ori[bad_Y_index], Y_output_ori[bad_Y_index], X_output_ori[bad_Y_index]), output_gp[bad_Y_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_output_scale.min(), good_output_scale.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_output_scale.min(), bad_output_scale.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(good_input_scale, bins=40, alpha=0.6, label='good input')\n",
    "plt.hist(bad_input_scale, bins=40, alpha=0.6, label='bad input')\n",
    "plt.yscale('linear')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(good_output_scale, bins=40, alpha=0.6, label='good output')\n",
    "plt.hist(bad_output_scale, bins=40, alpha=0.6, label='bad output')\n",
    "plt.yscale('linear')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(good_input_scale, bins=40, alpha=0.6, label='good input')\n",
    "plt.hist(bad_input_scale, bins=40, alpha=0.6, label='bad input')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.hist(good_output_scale, bins=40, alpha=0.6, label='good output')\n",
    "plt.hist(bad_output_scale, bins=40, alpha=0.6, label='bad output')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.hist(good_input_scale, bins=100, range=(0,0.8), alpha=0.6, label='good input')\n",
    "plt.hist(good_output_scale, bins=100, range=(0,0.8), alpha=0.6, label='good output')\n",
    "plt.hist(bad_input_scale, bins=100, range=(0,0.8), alpha=0.6, label='bad input')\n",
    "plt.hist(bad_output_scale, bins=100, range=(0,0.8), alpha=0.6, label='bad output')\n",
    "plt.yscale('linear')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should we split the data into std > and < 1.7 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(good_output_scale), np.mean(good_input_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(bad_output_scale), np.mean(bad_input_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.hist(bad_input_scale, bins=60, range=(0,0.8), alpha=0.6, label='bad input')\n",
    "plt.hist(bad_output_scale, bins=60, range=(0,0.8), alpha=0.6, label='bad output')\n",
    "plt.yscale('linear')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.hist(output_scale, bins=40, alpha=0.6, label='output')\n",
    "plt.hist(input_scale, bins=40, alpha=0.6, label='input')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.histogram(output_scale, bins=np.arange(0,1,0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.hist(good_input_center, bins=100, range=(0,5), alpha=0.6, label='good input')\n",
    "plt.hist(good_output_center, bins=100, range=(0,5), alpha=0.6, label='good output')\n",
    "plt.hist(bad_input_center, bins=100, range=(0,5), alpha=0.6, label='bad input')\n",
    "plt.hist(bad_output_center, bins=100, range=(0,5), alpha=0.6, label='bad output')\n",
    "plt.yscale('linear')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stdev/median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output_factor_1 = (output_center / output_scale).reshape(-1); output_factor_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output_factor_1.min(), output_factor_1.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.hist(output_factor_1, bins=40, range=[0,50], alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.scatter(smape_Y_pred, output_scale, alpha=0.1, marker='.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12,9))\n",
    "plt.scatter(smape_Y_pred, output_center, alpha=0.1, marker='.')\n",
    "plt.ylim([-0.1,5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12,9))\n",
    "plt.scatter(smape_Y_pred, output_scale, alpha=0.1, marker='.')\n",
    "plt.ylim([0,0.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12,9))\n",
    "plt.scatter(output_scale, output_center, alpha=0.1, marker='.')\n",
    "plt.ylim([0,4.5])\n",
    "plt.xlim([0,0.6])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output_factor_2 = (output_scale / output_center).reshape(-1); output_factor_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12,9))\n",
    "plt.scatter(smape_Y_pred, output_factor_2, alpha=0.1, marker='.')\n",
    "plt.ylim([0,0.8])\n",
    "#plt.xlim([0,0.6])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output_factor_3 = (output_scale / (output_center + 0.01)).reshape(-1); output_factor_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12,9))\n",
    "plt.scatter(smape_Y_pred, output_factor_3, alpha=0.1, marker='.')\n",
    "plt.ylim([0,4])\n",
    "#plt.xlim([0,0.6])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output_factor_4 = output_scale - input_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12,9))\n",
    "plt.scatter(smape_Y_pred, output_factor_4, alpha=0.1, marker='.')\n",
    "plt.ylim([-1.5,0.5])\n",
    "#plt.xlim([0,0.6])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Prediction\n",
    "For predicting stage only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "predict_dates_index=pd.date_range(Y_output_first_day, \n",
    "                                  periods=np.timedelta64(y_length,'D'), \n",
    "                                  freq = 'D', unit = 'D')\n",
    "predict_dates_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_output_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if test_length == 0:\n",
    "    result_df = pd.DataFrame(Y_output_fmc_ori, columns = Y_output_dates)  # using combined result\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_df['Page'] = input_df['Page']  # Append 'Page' column from input_df\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_flat_df = pd.melt(result_df, id_vars='Page', var_name='date',\n",
    "                         value_name='Visits')\n",
    "result_flat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if test_length == 0:\n",
    "    print('%%% Reading data key_1.csv ...', end = '', flush = True)\n",
    "    output_df = pd.read_csv(\"../data/key_1.csv\")\n",
    "    print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_df['date'] = output_df.Page.apply(lambda a: a[-10:])  # take the last 10 characters from 'Page' as date\n",
    "output_df['Page'] = output_df.Page.apply(lambda a: a[:-11])  # remove the last 10 caharacters from 'Page'\n",
    "#output_df['date'] = output_df['date'].astype('datetime64[ns]')  # convert 'date' string to numpy datetime format\n",
    "#test['weekday'] = test.date.dt.dayofweek  # find the day of week using the 'date' column\n",
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_df['date'].values[0:62]  # Make sure the range is 60 days (see if the dates resume after 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_output_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_df = output_df.merge(result_flat_df, how='left')  # fill the 'Visits\" from result\n",
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del result_flat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Check if there is null value\n",
    "output_df.loc[output_df.Visits.isnull(), 'Visits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#output_df.loc[output_df.Visits.isnull(), 'Visits'] = 0.0  # Uncommend this line to Replace NaN with 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('%%% Writing result for ' + model_name + ' ...', \n",
    "      end = '', flush = True)\n",
    "#Write only the 'Id' and 'Visits' to the result file\n",
    "output_df[['Id','Visits']].to_csv('../results/submit_1_' + model_name\n",
    "                                  + '.csv', index = False, \n",
    "                                  float_format='%.3f')\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle LB Score: \n",
    "\n",
    "[6.0.0] 46.3 [Model 6.0.0 CNN - Conv(60, 7)-FC(120)-Drop(0.25)-FC(120)-Drop(0.5)-Linear, 20 epoches]\n",
    "\n",
    "[6.1.0] 46.7 [Model 6.1.0 CNN - Conv(30, 7)-Conv(60, 7)-FC(120)-Drop(0.25)-FC(120)-Drop(0.5)-Linear, 20 epoches]\n",
    "\n",
    "[7.1.2] 47.3 [Model 7.1.2 CNN Fibonacci - range corrected :-y_length - score corrected]\n",
    "\n",
    "[7.2.0] 46.5 [Model 7.2.0 CNN Fibonacci and original combined]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
